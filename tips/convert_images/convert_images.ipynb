{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像ファイルを Keras / Tensorflow で読み込める形式に変換して保存する\n",
    "\n",
    "## 概要\n",
    "\n",
    "このノートブックでは，SageMaker 上で画像ファイルを読み込んで，学習ジョブに適した形に変換する 2 つの例を説明します．\n",
    "\n",
    "- numpy の ndarray 形式に変換して保存\n",
    "- tfrecords に変換して保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を扱うモジュールである PIL をインストール\n",
    "!pip install --upgrade pip && pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備\n",
    "\n",
    "png 形式の MNIST データをダウンロードする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -r data &&\\\n",
    "mkdir -p data &&\\\n",
    "cd data &&\\\n",
    "git clone https://github.com/myleott/mnist_png.git &&\\\n",
    "tar zxf mnist_png/mnist_png.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy 形式で保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データを ndarray にして格納するための配列の定義\n",
    "x_train = np.empty((0, 28, 28), int)\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ファイルからデータを読み込んで ndarray に格納する．ここでは，データ量を間引くために，画像ファイルのうち \"11\" が頭につく png ファイルだけを抜き出して，訓練データとして使うことにしている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile('.*(\\d+)\\/.*')\n",
    "file_pathes = glob.glob('data/mnist_png/training/*/11*')\n",
    "\n",
    "for file_path in file_pathes:\n",
    "    image = Image.open(file_path)\n",
    "    image_array = np.asarray(image)\n",
    "    x_train = np.append(x_train, [image_array], axis=0)\n",
    "    m = r.search(file_path)\n",
    "    y_train.append(m.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の保存\n",
    "np.savez('train_data', image=x_train, label=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfrecords 形式で保存\n",
    "\n",
    "Tensorflow で効率的に読みだすための tfrecords 形式に変換する場合，下記のような形でシリアライズを行う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to(images, labels, name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    num_examples = len(labels)\n",
    "\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError('Images size %d does not match label size %d.' %\n",
    "                         (images.shape[0], num_examples))\n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "\n",
    "    filename = os.path.join(name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': tf.train.Feature(int64_list=tf.train.Int64List(value=[rows])),\n",
    "            'width': tf.train.Feature(int64_list=tf.train.Int64List(value=[cols])),\n",
    "            'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[int(labels[index])])),\n",
    "            'image_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image_raw]))}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to(x_train, y_train, 'train_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
