{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAIRSeq in Amazon SageMaker: Translation task - German to English - Distributed / multi machine training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Facebook AI Research (FAIR) Lab made available through the [FAIRSeq toolkit](https://github.com/pytorch/fairseq) their state-of-the-art Sequence to Sequence models. \n",
    "\n",
    "In this notebook, we will show you how to train a German to English translation model using a fully convolutional architecture on multiple GPUs and machines.\n",
    "\n",
    "## Permissions\n",
    "\n",
    "Running this notebook requires permissions in addition to the regular SageMakerFullAccess permissions. This is because it creates new repositories in Amazon ECR. The easiest way to add these permissions is simply to add the managed policy AmazonEC2ContainerRegistryFullAccess to the role that you used to start your notebook instance. There's no need to restart your notebook instance when you do this, the new permissions will be available immediately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "To train the model, we will be using the IWSLT'14 dataset as descibed [here](https://github.com/pytorch/fairseq/tree/master/examples/translation#prepare-iwslt14sh). This was used in the IWSLT'14 German to English translation task: [\"Report on the 11th IWSLT evaluation campaign\" by Cettolo et al](http://workshop2014.iwslt.org/downloads/proceeding.pdf).\n",
    "\n",
    "First, we'll download the dataset and start the pre-processing. Among other steps, this pre-processing cleans the tokens and applys BPE encoding as you can see [here](https://github.com/pytorch/fairseq/blob/master/examples/translation/prepare-iwslt14.sh)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning Moses github repository (for tokenization scripts)...\n",
      "Cloning Subword NMT repository (for BPE pre-processing)...\n",
      "Downloading data from https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz...\n",
      "Data successfully downloaded.\n",
      "de-en/\n",
      "de-en/IWSLT14.TED.dev2010.de-en.de.xml\n",
      "de-en/IWSLT14.TED.dev2010.de-en.en.xml\n",
      "de-en/IWSLT14.TED.tst2010.de-en.de.xml\n",
      "de-en/IWSLT14.TED.tst2010.de-en.en.xml\n",
      "de-en/IWSLT14.TED.tst2011.de-en.de.xml\n",
      "de-en/IWSLT14.TED.tst2011.de-en.en.xml\n",
      "de-en/IWSLT14.TED.tst2012.de-en.de.xml\n",
      "de-en/IWSLT14.TED.tst2012.de-en.en.xml\n",
      "de-en/IWSLT14.TEDX.dev2012.de-en.de.xml\n",
      "de-en/IWSLT14.TEDX.dev2012.de-en.en.xml\n",
      "de-en/README\n",
      "de-en/train.en\n",
      "de-en/train.tags.de-en.de\n",
      "de-en/train.tags.de-en.en\n",
      "pre-processing train data...\n",
      "\n",
      "\n",
      "pre-processing valid/test data...\n",
      "orig/de-en/IWSLT14.TED.dev2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.de\n",
      "\n",
      "orig/de-en/IWSLT14.TED.tst2010.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.de\n",
      "\n",
      "orig/de-en/IWSLT14.TED.tst2011.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.de\n",
      "\n",
      "orig/de-en/IWSLT14.TED.tst2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.de\n",
      "\n",
      "orig/de-en/IWSLT14.TEDX.dev2012.de-en.de.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.de\n",
      "\n",
      "orig/de-en/IWSLT14.TED.dev2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.dev2010.de-en.en\n",
      "\n",
      "orig/de-en/IWSLT14.TED.tst2010.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2010.de-en.en\n",
      "\n",
      "orig/de-en/IWSLT14.TED.tst2011.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2011.de-en.en\n",
      "\n",
      "orig/de-en/IWSLT14.TED.tst2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TED.tst2012.de-en.en\n",
      "\n",
      "orig/de-en/IWSLT14.TEDX.dev2012.de-en.en.xml iwslt14.tokenized.de-en/tmp/IWSLT14.TEDX.dev2012.de-en.en\n",
      "\n",
      "creating train, valid, test...\n",
      "learn_bpe.py on iwslt14.tokenized.de-en/tmp/train.en-de...\n",
      "apply_bpe.py to train.de...\n",
      "apply_bpe.py to valid.de...\n",
      "apply_bpe.py to test.de...\n",
      "apply_bpe.py to train.en...\n",
      "apply_bpe.py to valid.en...\n",
      "apply_bpe.py to test.en...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'mosesdecoder'...\n",
      "Cloning into 'subword-nmt'...\n",
      "--2019-06-28 21:12:43--  https://wit3.fbk.eu/archive/2014-01/texts/de/en/de-en.tgz\n",
      "Resolving wit3.fbk.eu (wit3.fbk.eu)... 217.77.80.8\n",
      "Connecting to wit3.fbk.eu (wit3.fbk.eu)|217.77.80.8|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19982877 (19M) [application/x-gzip]\n",
      "Saving to: ‘de-en.tgz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  148K 2m11s\n",
      "    50K .......... .......... .......... .......... ..........  0%  446K 87s\n",
      "   100K .......... .......... .......... .......... ..........  0%  447K 72s\n",
      "   150K .......... .......... .......... .......... ..........  1% 99.7M 54s\n",
      "   200K .......... .......... .......... .......... ..........  1%  448K 52s\n",
      "   250K .......... .......... .......... .......... ..........  1%  101M 43s\n",
      "   300K .......... .......... .......... .......... ..........  1% 90.8M 37s\n",
      "   350K .......... .......... .......... .......... ..........  2%  451K 37s\n",
      "   400K .......... .......... .......... .......... ..........  2% 67.7M 33s\n",
      "   450K .......... .......... .......... .......... ..........  2% 92.5M 30s\n",
      "   500K .......... .......... .......... .......... ..........  2% 1.29M 28s\n",
      "   550K .......... .......... .......... .......... ..........  3%  683K 28s\n",
      "   600K .......... .......... .......... .......... ..........  3% 96.7M 26s\n",
      "   650K .......... .......... .......... .......... ..........  3% 88.9M 24s\n",
      "   700K .......... .......... .......... .......... ..........  3% 90.5M 22s\n",
      "   750K .......... .......... .......... .......... ..........  4% 95.0M 21s\n",
      "   800K .......... .......... .......... .......... ..........  4%  456K 22s\n",
      "   850K .......... .......... .......... .......... ..........  4% 89.5M 21s\n",
      "   900K .......... .......... .......... .......... ..........  4% 93.2M 20s\n",
      "   950K .......... .......... .......... .......... ..........  5% 97.3M 19s\n",
      "  1000K .......... .......... .......... .......... ..........  5% 85.6M 18s\n",
      "  1050K .......... .......... .......... .......... ..........  5% 98.4M 17s\n",
      "  1100K .......... .......... .......... .......... ..........  5% 94.4M 16s\n",
      "  1150K .......... .......... .......... .......... ..........  6%  460K 17s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 66.9M 16s\n",
      "  1250K .......... .......... .......... .......... ..........  6% 89.7M 16s\n",
      "  1300K .......... .......... .......... .......... ..........  6% 91.1M 15s\n",
      "  1350K .......... .......... .......... .......... ..........  7% 85.6M 15s\n",
      "  1400K .......... .......... .......... .......... ..........  7% 81.7M 14s\n",
      "  1450K .......... .......... .......... .......... ..........  7% 89.5M 13s\n",
      "  1500K .......... .......... .......... .......... ..........  7% 96.6M 13s\n",
      "  1550K .......... .......... .......... .......... ..........  8% 82.1M 13s\n",
      "  1600K .......... .......... .......... .......... ..........  8% 66.4M 12s\n",
      "  1650K .......... .......... .......... .......... ..........  8% 1.41M 12s\n",
      "  1700K .......... .......... .......... .......... ..........  8%  693K 13s\n",
      "  1750K .......... .......... .......... .......... ..........  9% 88.9M 12s\n",
      "  1800K .......... .......... .......... .......... ..........  9% 91.6M 12s\n",
      "  1850K .......... .......... .......... .......... ..........  9% 98.4M 11s\n",
      "  1900K .......... .......... .......... .......... ..........  9% 92.2M 11s\n",
      "  1950K .......... .......... .......... .......... .......... 10% 84.4M 11s\n",
      "  2000K .......... .......... .......... .......... .......... 10% 78.0M 11s\n",
      "  2050K .......... .......... .......... .......... .......... 10% 88.3M 10s\n",
      "  2100K .......... .......... .......... .......... .......... 11% 92.7M 10s\n",
      "  2150K .......... .......... .......... .......... .......... 11% 88.0M 10s\n",
      "  2200K .......... .......... .......... .......... .......... 11% 90.5M 10s\n",
      "  2250K .......... .......... .......... .......... .......... 11% 90.6M 9s\n",
      "  2300K .......... .......... .......... .......... .......... 12% 83.9M 9s\n",
      "  2350K .......... .......... .......... .......... .......... 12% 1.48M 9s\n",
      "  2400K .......... .......... .......... .......... .......... 12%  693K 9s\n",
      "  2450K .......... .......... .......... .......... .......... 12% 81.4M 9s\n",
      "  2500K .......... .......... .......... .......... .......... 13%  105M 9s\n",
      "  2550K .......... .......... .......... .......... .......... 13% 93.1M 9s\n",
      "  2600K .......... .......... .......... .......... .......... 13% 82.2M 9s\n",
      "  2650K .......... .......... .......... .......... .......... 13% 72.0M 8s\n",
      "  2700K .......... .......... .......... .......... .......... 14% 97.2M 8s\n",
      "  2750K .......... .......... .......... .......... .......... 14% 87.3M 8s\n",
      "  2800K .......... .......... .......... .......... .......... 14% 69.8M 8s\n",
      "  2850K .......... .......... .......... .......... .......... 14% 97.5M 8s\n",
      "  2900K .......... .......... .......... .......... .......... 15% 91.8M 8s\n",
      "  2950K .......... .......... .......... .......... .......... 15% 94.2M 7s\n",
      "  3000K .......... .......... .......... .......... .......... 15% 82.1M 7s\n",
      "  3050K .......... .......... .......... .......... .......... 15% 89.4M 7s\n",
      "  3100K .......... .......... .......... .......... .......... 16% 90.8M 7s\n",
      "  3150K .......... .......... .......... .......... .......... 16% 92.6M 7s\n",
      "  3200K .......... .......... .......... .......... .......... 16% 67.1M 7s\n",
      "  3250K .......... .......... .......... .......... .......... 16% 93.6M 7s\n",
      "  3300K .......... .......... .......... .......... .......... 17% 95.1M 7s\n",
      "  3350K .......... .......... .......... .......... .......... 17% 1.64M 7s\n",
      "  3400K .......... .......... .......... .......... .......... 17% 85.2M 6s\n",
      "  3450K .......... .......... .......... .......... .......... 17%  697K 7s\n",
      "  3500K .......... .......... .......... .......... .......... 18% 90.6M 7s\n",
      "  3550K .......... .......... .......... .......... .......... 18% 85.4M 6s\n",
      "  3600K .......... .......... .......... .......... .......... 18% 69.0M 6s\n",
      "  3650K .......... .......... .......... .......... .......... 18% 87.7M 6s\n",
      "  3700K .......... .......... .......... .......... .......... 19% 88.2M 6s\n",
      "  3750K .......... .......... .......... .......... .......... 19% 85.6M 6s\n",
      "  3800K .......... .......... .......... .......... .......... 19% 85.1M 6s\n",
      "  3850K .......... .......... .......... .......... .......... 19% 98.1M 6s\n",
      "  3900K .......... .......... .......... .......... .......... 20% 86.2M 6s\n",
      "  3950K .......... .......... .......... .......... .......... 20% 93.3M 6s\n",
      "  4000K .......... .......... .......... .......... .......... 20% 69.9M 6s\n",
      "  4050K .......... .......... .......... .......... .......... 21% 92.0M 6s\n",
      "  4100K .......... .......... .......... .......... .......... 21% 86.4M 5s\n",
      "  4150K .......... .......... .......... .......... .......... 21% 91.2M 5s\n",
      "  4200K .......... .......... .......... .......... .......... 21% 89.7M 5s\n",
      "  4250K .......... .......... .......... .......... .......... 22%  103M 5s\n",
      "  4300K .......... .......... .......... .......... .......... 22% 96.4M 5s\n",
      "  4350K .......... .......... .......... .......... .......... 22% 83.7M 5s\n",
      "  4400K .......... .......... .......... .......... .......... 22% 69.6M 5s\n",
      "  4450K .......... .......... .......... .......... .......... 23% 86.8M 5s\n",
      "  4500K .......... .......... .......... .......... .......... 23% 82.9M 5s\n",
      "  4550K .......... .......... .......... .......... .......... 23% 93.3M 5s\n",
      "  4600K .......... .......... .......... .......... .......... 23% 90.9M 5s\n",
      "  4650K .......... .......... .......... .......... .......... 24% 86.2M 5s\n",
      "  4700K .......... .......... .......... .......... .......... 24% 92.3M 5s\n",
      "  4750K .......... .......... .......... .......... .......... 24% 1.89M 5s\n",
      "  4800K .......... .......... .......... .......... .......... 24% 73.5M 5s\n",
      "  4850K .......... .......... .......... .......... .......... 25%  700K 5s\n",
      "  4900K .......... .......... .......... .......... .......... 25% 95.0M 5s\n",
      "  4950K .......... .......... .......... .......... .......... 25% 85.4M 5s\n",
      "  5000K .......... .......... .......... .......... .......... 25% 84.6M 4s\n",
      "  5050K .......... .......... .......... .......... .......... 26% 91.1M 4s\n",
      "  5100K .......... .......... .......... .......... .......... 26% 87.9M 4s\n",
      "  5150K .......... .......... .......... .......... .......... 26% 89.4M 4s\n",
      "  5200K .......... .......... .......... .......... .......... 26% 65.2M 4s\n",
      "  5250K .......... .......... .......... .......... .......... 27% 90.3M 4s\n",
      "  5300K .......... .......... .......... .......... .......... 27% 90.6M 4s\n",
      "  5350K .......... .......... .......... .......... .......... 27% 91.1M 4s\n",
      "  5400K .......... .......... .......... .......... .......... 27% 80.3M 4s\n",
      "  5450K .......... .......... .......... .......... .......... 28% 92.6M 4s\n",
      "  5500K .......... .......... .......... .......... .......... 28% 82.9M 4s\n",
      "  5550K .......... .......... .......... .......... .......... 28% 94.9M 4s\n",
      "  5600K .......... .......... .......... .......... .......... 28% 70.4M 4s\n",
      "  5650K .......... .......... .......... .......... .......... 29% 91.7M 4s\n",
      "  5700K .......... .......... .......... .......... .......... 29% 87.6M 4s\n",
      "  5750K .......... .......... .......... .......... .......... 29% 88.2M 4s\n",
      "  5800K .......... .......... .......... .......... .......... 29% 90.3M 4s\n",
      "  5850K .......... .......... .......... .......... .......... 30% 90.7M 4s\n",
      "  5900K .......... .......... .......... .......... .......... 30% 81.1M 4s\n",
      "  5950K .......... .......... .......... .......... .......... 30% 90.5M 4s\n",
      "  6000K .......... .......... .......... .......... .......... 31% 70.5M 4s\n",
      "  6050K .......... .......... .......... .......... .......... 31% 93.1M 3s\n",
      "  6100K .......... .......... .......... .......... .......... 31% 85.0M 3s\n",
      "  6150K .......... .......... .......... .......... .......... 31% 99.5M 3s\n",
      "  6200K .......... .......... .......... .......... .......... 32% 83.6M 3s\n",
      "  6250K .......... .......... .......... .......... .......... 32% 2.03M 3s\n",
      "  6300K .......... .......... .......... .......... .......... 32% 71.8M 3s\n",
      "  6350K .......... .......... .......... .......... .......... 32% 93.8M 3s\n",
      "  6400K .......... .......... .......... .......... .......... 33%  699K 3s\n",
      "  6450K .......... .......... .......... .......... .......... 33% 76.1M 3s\n",
      "  6500K .......... .......... .......... .......... .......... 33% 93.1M 3s\n",
      "  6550K .......... .......... .......... .......... .......... 33% 82.8M 3s\n",
      "  6600K .......... .......... .......... .......... .......... 34% 90.4M 3s\n",
      "  6650K .......... .......... .......... .......... .......... 34% 81.6M 3s\n",
      "  6700K .......... .......... .......... .......... .......... 34%  104M 3s\n",
      "  6750K .......... .......... .......... .......... .......... 34% 87.1M 3s\n",
      "  6800K .......... .......... .......... .......... .......... 35% 72.8M 3s\n",
      "  6850K .......... .......... .......... .......... .......... 35% 73.1M 3s\n",
      "  6900K .......... .......... .......... .......... .......... 35% 81.6M 3s\n",
      "  6950K .......... .......... .......... .......... .......... 35%  103M 3s\n",
      "  7000K .......... .......... .......... .......... .......... 36% 84.8M 3s\n",
      "  7050K .......... .......... .......... .......... .......... 36% 93.3M 3s\n",
      "  7100K .......... .......... .......... .......... .......... 36% 96.9M 3s\n",
      "  7150K .......... .......... .......... .......... .......... 36% 87.6M 3s\n",
      "  7200K .......... .......... .......... .......... .......... 37% 72.9M 3s\n",
      "  7250K .......... .......... .......... .......... .......... 37% 93.1M 3s\n",
      "  7300K .......... .......... .......... .......... .......... 37% 98.1M 3s\n",
      "  7350K .......... .......... .......... .......... .......... 37% 92.5M 3s\n",
      "  7400K .......... .......... .......... .......... .......... 38% 84.4M 3s\n",
      "  7450K .......... .......... .......... .......... .......... 38% 84.8M 3s\n",
      "  7500K .......... .......... .......... .......... .......... 38% 77.0M 3s\n",
      "  7550K .......... .......... .......... .......... .......... 38% 87.2M 3s\n",
      "  7600K .......... .......... .......... .......... .......... 39% 66.1M 3s\n",
      "  7650K .......... .......... .......... .......... .......... 39% 90.7M 3s\n",
      "  7700K .......... .......... .......... .......... .......... 39% 97.0M 3s\n",
      "  7750K .......... .......... .......... .......... .......... 39% 98.1M 3s\n",
      "  7800K .......... .......... .......... .......... .......... 40% 2.02M 3s\n",
      "  7850K .......... .......... .......... .......... .......... 40% 94.8M 3s\n",
      "  7900K .......... .......... .......... .......... .......... 40% 1.13M 3s\n",
      "  7950K .......... .......... .......... .......... .......... 40% 1.71M 3s\n",
      "  8000K .......... .......... .......... .......... .......... 41% 44.8M 3s\n",
      "  8050K .......... .......... .......... .......... .......... 41% 91.6M 3s\n",
      "  8100K .......... .......... .......... .......... .......... 41% 97.2M 3s\n",
      "  8150K .......... .......... .......... .......... .......... 42% 89.1M 2s\n",
      "  8200K .......... .......... .......... .......... .......... 42% 89.0M 2s\n",
      "  8250K .......... .......... .......... .......... .......... 42% 91.8M 2s\n",
      "  8300K .......... .......... .......... .......... .......... 42% 87.3M 2s\n",
      "  8350K .......... .......... .......... .......... .......... 43% 94.7M 2s\n",
      "  8400K .......... .......... .......... .......... .......... 43% 67.9M 2s\n",
      "  8450K .......... .......... .......... .......... .......... 43% 89.4M 2s\n",
      "  8500K .......... .......... .......... .......... .......... 43% 85.8M 2s\n",
      "  8550K .......... .......... .......... .......... .......... 44% 89.5M 2s\n",
      "  8600K .......... .......... .......... .......... .......... 44% 97.6M 2s\n",
      "  8650K .......... .......... .......... .......... .......... 44% 86.6M 2s\n",
      "  8700K .......... .......... .......... .......... .......... 44% 93.0M 2s\n",
      "  8750K .......... .......... .......... .......... .......... 45% 90.5M 2s\n",
      "  8800K .......... .......... .......... .......... .......... 45% 67.1M 2s\n",
      "  8850K .......... .......... .......... .......... .......... 45% 96.4M 2s\n",
      "  8900K .......... .......... .......... .......... .......... 45% 95.5M 2s\n",
      "  8950K .......... .......... .......... .......... .......... 46% 93.2M 2s\n",
      "  9000K .......... .......... .......... .......... .......... 46% 82.3M 2s\n",
      "  9050K .......... .......... .......... .......... .......... 46% 87.6M 2s\n",
      "  9100K .......... .......... .......... .......... .......... 46% 95.7M 2s\n",
      "  9150K .......... .......... .......... .......... .......... 47% 80.9M 2s\n",
      "  9200K .......... .......... .......... .......... .......... 47% 67.0M 2s\n",
      "  9250K .......... .......... .......... .......... .......... 47% 87.2M 2s\n",
      "  9300K .......... .......... .......... .......... .......... 47% 36.6M 2s\n",
      "  9350K .......... .......... .......... .......... .......... 48% 2.11M 2s\n",
      "  9400K .......... .......... .......... .......... .......... 48% 84.0M 2s\n",
      "  9450K .......... .......... .......... .......... .......... 48%  699K 2s\n",
      "  9500K .......... .......... .......... .......... .......... 48% 85.3M 2s\n",
      "  9550K .......... .......... .......... .......... .......... 49% 70.2M 2s\n",
      "  9600K .......... .......... .......... .......... .......... 49% 60.3M 2s\n",
      "  9650K .......... .......... .......... .......... .......... 49%  109M 2s\n",
      "  9700K .......... .......... .......... .......... .......... 49% 91.1M 2s\n",
      "  9750K .......... .......... .......... .......... .......... 50% 84.6M 2s\n",
      "  9800K .......... .......... .......... .......... .......... 50% 49.4M 2s\n",
      "  9850K .......... .......... .......... .......... .......... 50% 93.8M 2s\n",
      "  9900K .......... .......... .......... .......... .......... 50% 88.4M 2s\n",
      "  9950K .......... .......... .......... .......... .......... 51% 94.4M 2s\n",
      " 10000K .......... .......... .......... .......... .......... 51% 67.5M 2s\n",
      " 10050K .......... .......... .......... .......... .......... 51% 92.8M 2s\n",
      " 10100K .......... .......... .......... .......... .......... 52% 94.2M 2s\n",
      " 10150K .......... .......... .......... .......... .......... 52% 93.4M 2s\n",
      " 10200K .......... .......... .......... .......... .......... 52% 96.1M 2s\n",
      " 10250K .......... .......... .......... .......... .......... 52% 93.7M 2s\n",
      " 10300K .......... .......... .......... .......... .......... 53%  102M 2s\n",
      " 10350K .......... .......... .......... .......... .......... 53% 86.0M 2s\n",
      " 10400K .......... .......... .......... .......... .......... 53% 74.7M 2s\n",
      " 10450K .......... .......... .......... .......... .......... 53% 96.6M 2s\n",
      " 10500K .......... .......... .......... .......... .......... 54% 92.0M 2s\n",
      " 10550K .......... .......... .......... .......... .......... 54% 96.0M 2s\n",
      " 10600K .......... .......... .......... .......... .......... 54% 85.1M 2s\n",
      " 10650K .......... .......... .......... .......... .......... 54% 95.7M 2s\n",
      " 10700K .......... .......... .......... .......... .......... 55% 84.8M 2s\n",
      " 10750K .......... .......... .......... .......... .......... 55% 97.3M 2s\n",
      " 10800K .......... .......... .......... .......... .......... 55% 71.4M 2s\n",
      " 10850K .......... .......... .......... .......... .......... 55% 7.65M 2s\n",
      " 10900K .......... .......... .......... .......... .......... 56% 2.70M 2s\n",
      " 10950K .......... .......... .......... .......... .......... 56%  696K 2s\n",
      " 11000K .......... .......... .......... .......... .......... 56% 79.0M 2s\n",
      " 11050K .......... .......... .......... .......... .......... 56% 92.4M 2s\n",
      " 11100K .......... .......... .......... .......... .......... 57% 98.6M 2s\n",
      " 11150K .......... .......... .......... .......... .......... 57% 78.1M 1s\n",
      " 11200K .......... .......... .......... .......... .......... 57% 84.4M 1s\n",
      " 11250K .......... .......... .......... .......... .......... 57% 85.2M 1s\n",
      " 11300K .......... .......... .......... .......... .......... 58% 60.6M 1s\n",
      " 11350K .......... .......... .......... .......... .......... 58% 76.9M 1s\n",
      " 11400K .......... .......... .......... .......... .......... 58% 68.6M 1s\n",
      " 11450K .......... .......... .......... .......... .......... 58% 95.1M 1s\n",
      " 11500K .......... .......... .......... .......... .......... 59% 85.4M 1s\n",
      " 11550K .......... .......... .......... .......... .......... 59% 95.1M 1s\n",
      " 11600K .......... .......... .......... .......... .......... 59% 72.6M 1s\n",
      " 11650K .......... .......... .......... .......... .......... 59% 87.7M 1s\n",
      " 11700K .......... .......... .......... .......... .......... 60% 96.3M 1s\n",
      " 11750K .......... .......... .......... .......... .......... 60% 97.3M 1s\n",
      " 11800K .......... .......... .......... .......... .......... 60% 88.6M 1s\n",
      " 11850K .......... .......... .......... .......... .......... 60% 91.9M 1s\n",
      " 11900K .......... .......... .......... .......... .......... 61% 85.6M 1s\n",
      " 11950K .......... .......... .......... .......... .......... 61% 96.9M 1s\n",
      " 12000K .......... .......... .......... .......... .......... 61% 77.5M 1s\n",
      " 12050K .......... .......... .......... .......... .......... 62% 89.2M 1s\n",
      " 12100K .......... .......... .......... .......... .......... 62% 88.5M 1s\n",
      " 12150K .......... .......... .......... .......... .......... 62% 94.5M 1s\n",
      " 12200K .......... .......... .......... .......... .......... 62% 78.1M 1s\n",
      " 12250K .......... .......... .......... .......... .......... 63% 91.4M 1s\n",
      " 12300K .......... .......... .......... .......... .......... 63% 87.5M 1s\n",
      " 12350K .......... .......... .......... .......... .......... 63% 97.6M 1s\n",
      " 12400K .......... .......... .......... .......... .......... 63% 1.48M 1s\n",
      " 12450K .......... .......... .......... .......... .......... 64%  271M 1s\n",
      " 12500K .......... .......... .......... .......... .......... 64%  794K 1s\n",
      " 12550K .......... .......... .......... .......... .......... 64% 96.0M 1s\n",
      " 12600K .......... .......... .......... .......... .......... 64% 84.1M 1s\n",
      " 12650K .......... .......... .......... .......... .......... 65% 81.3M 1s\n",
      " 12700K .......... .......... .......... .......... .......... 65% 92.8M 1s\n",
      " 12750K .......... .......... .......... .......... .......... 65% 76.1M 1s\n",
      " 12800K .......... .......... .......... .......... .......... 65% 69.7M 1s\n",
      " 12850K .......... .......... .......... .......... .......... 66% 77.1M 1s\n",
      " 12900K .......... .......... .......... .......... .......... 66% 67.6M 1s\n",
      " 12950K .......... .......... .......... .......... .......... 66% 89.1M 1s\n",
      " 13000K .......... .......... .......... .......... .......... 66% 92.5M 1s\n",
      " 13050K .......... .......... .......... .......... .......... 67% 68.5M 1s\n",
      " 13100K .......... .......... .......... .......... .......... 67% 88.5M 1s\n",
      " 13150K .......... .......... .......... .......... .......... 67% 91.2M 1s\n",
      " 13200K .......... .......... .......... .......... .......... 67% 74.8M 1s\n",
      " 13250K .......... .......... .......... .......... .......... 68% 88.5M 1s\n",
      " 13300K .......... .......... .......... .......... .......... 68% 93.7M 1s\n",
      " 13350K .......... .......... .......... .......... .......... 68% 91.0M 1s\n",
      " 13400K .......... .......... .......... .......... .......... 68% 91.3M 1s\n",
      " 13450K .......... .......... .......... .......... .......... 69% 93.5M 1s\n",
      " 13500K .......... .......... .......... .......... .......... 69% 89.2M 1s\n",
      " 13550K .......... .......... .......... .......... .......... 69% 89.4M 1s\n",
      " 13600K .......... .......... .......... .......... .......... 69% 64.1M 1s\n",
      " 13650K .......... .......... .......... .......... .......... 70% 79.5M 1s\n",
      " 13700K .......... .......... .......... .......... .......... 70% 92.3M 1s\n",
      " 13750K .......... .......... .......... .......... .......... 70% 93.4M 1s\n",
      " 13800K .......... .......... .......... .......... .......... 70% 96.2M 1s\n",
      " 13850K .......... .......... .......... .......... .......... 71% 95.2M 1s\n",
      " 13900K .......... .......... .......... .......... .......... 71% 24.6M 1s\n",
      " 13950K .......... .......... .......... .......... .......... 71% 1.55M 1s\n",
      " 14000K .......... .......... .......... .......... .......... 71%  789K 1s\n",
      " 14050K .......... .......... .......... .......... .......... 72%  224M 1s\n",
      " 14100K .......... .......... .......... .......... .......... 72%  254M 1s\n",
      " 14150K .......... .......... .......... .......... .......... 72%  120M 1s\n",
      " 14200K .......... .......... .......... .......... .......... 73% 62.2M 1s\n",
      " 14250K .......... .......... .......... .......... .......... 73% 78.6M 1s\n",
      " 14300K .......... .......... .......... .......... .......... 73% 85.2M 1s\n",
      " 14350K .......... .......... .......... .......... .......... 73% 91.1M 1s\n",
      " 14400K .......... .......... .......... .......... .......... 74% 54.5M 1s\n",
      " 14450K .......... .......... .......... .......... .......... 74% 89.8M 1s\n",
      " 14500K .......... .......... .......... .......... .......... 74% 34.9M 1s\n",
      " 14550K .......... .......... .......... .......... .......... 74% 92.3M 1s\n",
      " 14600K .......... .......... .......... .......... .......... 75% 85.5M 1s\n",
      " 14650K .......... .......... .......... .......... .......... 75% 99.1M 1s\n",
      " 14700K .......... .......... .......... .......... .......... 75% 92.0M 1s\n",
      " 14750K .......... .......... .......... .......... .......... 75% 88.7M 1s\n",
      " 14800K .......... .......... .......... .......... .......... 76% 75.0M 1s\n",
      " 14850K .......... .......... .......... .......... .......... 76% 86.6M 1s\n",
      " 14900K .......... .......... .......... .......... .......... 76% 88.3M 1s\n",
      " 14950K .......... .......... .......... .......... .......... 76% 92.6M 1s\n",
      " 15000K .......... .......... .......... .......... .......... 77% 92.9M 1s\n",
      " 15050K .......... .......... .......... .......... .......... 77% 88.2M 1s\n",
      " 15100K .......... .......... .......... .......... .......... 77% 92.2M 1s\n",
      " 15150K .......... .......... .......... .......... .......... 77% 90.3M 1s\n",
      " 15200K .......... .......... .......... .......... .......... 78% 70.0M 1s\n",
      " 15250K .......... .......... .......... .......... .......... 78% 89.5M 1s\n",
      " 15300K .......... .......... .......... .......... .......... 78% 86.7M 1s\n",
      " 15350K .......... .......... .......... .......... .......... 78% 91.9M 1s\n",
      " 15400K .......... .......... .......... .......... .......... 79% 85.8M 1s\n",
      " 15450K .......... .......... .......... .......... .......... 79% 15.5M 1s\n",
      " 15500K .......... .......... .......... .......... .......... 79% 1.66M 1s\n",
      " 15550K .......... .......... .......... .......... .......... 79%  791K 1s\n",
      " 15600K .......... .......... .......... .......... .......... 80% 67.4M 1s\n",
      " 15650K .......... .......... .......... .......... .......... 80% 83.4M 1s\n",
      " 15700K .......... .......... .......... .......... .......... 80% 98.2M 1s\n",
      " 15750K .......... .......... .......... .......... .......... 80% 89.4M 1s\n",
      " 15800K .......... .......... .......... .......... .......... 81% 81.6M 1s\n",
      " 15850K .......... .......... .......... .......... .......... 81% 83.9M 1s\n",
      " 15900K .......... .......... .......... .......... .......... 81%  104M 1s\n",
      " 15950K .......... .......... .......... .......... .......... 81% 85.3M 1s\n",
      " 16000K .......... .......... .......... .......... .......... 82% 39.2M 1s\n",
      " 16050K .......... .......... .......... .......... .......... 82% 68.9M 1s\n",
      " 16100K .......... .......... .......... .......... .......... 82% 85.5M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 83% 97.7M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 83% 75.3M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 83% 95.0M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 83% 87.8M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 84% 93.2M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 84% 72.8M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 84% 86.6M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 84% 97.9M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 85% 90.5M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 85% 81.6M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 85% 82.2M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 85%  100M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 86% 89.6M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 86% 73.8M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 86% 88.0M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 86% 95.8M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 87% 26.4M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 87% 1.59M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 87% 90.4M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 87%  792K 0s\n",
      " 17150K .......... .......... .......... .......... .......... 88% 97.7M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 88% 67.0M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 88% 98.0M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 88% 79.5M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 89% 95.8M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 89% 87.2M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 89% 85.0M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 89% 92.6M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 90% 48.8M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 90% 61.6M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 90% 73.2M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 90% 85.5M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 91% 93.4M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 91% 69.2M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 91% 88.6M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 91% 88.0M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 92%  101M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 92% 70.0M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 92% 97.3M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 93% 88.7M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 93% 96.2M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 93% 79.8M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 93% 90.9M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 94% 91.0M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 94% 91.6M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 94% 78.2M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 94% 88.4M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 95% 13.4M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 95% 1.69M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 95%  793K 0s\n",
      " 18650K .......... .......... .......... .......... .......... 95% 80.5M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 96% 74.9M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 96% 89.1M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 96% 75.4M 0s\n",
      " 18850K .......... .......... .......... .......... .......... 96% 52.2M 0s\n",
      " 18900K .......... .......... .......... .......... .......... 97% 89.8M 0s\n",
      " 18950K .......... .......... .......... .......... .......... 97% 91.9M 0s\n",
      " 19000K .......... .......... .......... .......... .......... 97% 88.7M 0s\n",
      " 19050K .......... .......... .......... .......... .......... 97% 94.0M 0s\n",
      " 19100K .......... .......... .......... .......... .......... 98% 68.4M 0s\n",
      " 19150K .......... .......... .......... .......... .......... 98% 78.0M 0s\n",
      " 19200K .......... .......... .......... .......... .......... 98% 59.0M 0s\n",
      " 19250K .......... .......... .......... .......... .......... 98% 89.1M 0s\n",
      " 19300K .......... .......... .......... .......... .......... 99% 88.1M 0s\n",
      " 19350K .......... .......... .......... .......... .......... 99% 68.0M 0s\n",
      " 19400K .......... .......... .......... .......... .......... 99% 83.4M 0s\n",
      " 19450K .......... .......... .......... .......... .......... 99% 90.9M 0s\n",
      " 19500K .......... ....                                       100%  165M=2.6s\n",
      "\n",
      "2019-06-28 21:12:47 (7.37 MB/s) - ‘de-en.tgz’ saved [19982877/19982877]\n",
      "\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "clean-corpus.perl: processing iwslt14.tokenized.de-en/tmp/train.tags.de-en.tok.de & .en to iwslt14.tokenized.de-en/tmp/train.tags.de-en.clean, cutoff 1-175, ratio 1.5\n",
      "..........(100000).......\n",
      "Input sentences: 174443  Output sentences:  167522\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: de\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "Tokenizer Version 1.1\n",
      "Language: en\n",
      "Number of threads: 8\n",
      "subword-nmt/learn_bpe.py:267: DeprecationWarning: this script's location has moved to /home/ec2-user/SageMaker/amazon-sagemaker-examples/advanced_functionality/fairseq_translation/data/subword-nmt/subword_nmt. This symbolic link will be removed in a future version. Please point to the new location, or install the package and use the command 'subword-nmt'\n",
      "  DeprecationWarning\n",
      "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
      "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
      "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
      "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
      "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
      "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
      "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
      "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
      "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
      "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n",
      "subword-nmt/apply_bpe.py:351: ResourceWarning: unclosed file <_io.TextIOWrapper name='iwslt14.tokenized.de-en/code' mode='r' encoding='UTF-8'>\n",
      "  args.codes = codecs.open(args.codes.name, encoding='utf-8')\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cd data\n",
    "chmod +x prepare-iwslt14.sh\n",
    "\n",
    "# Download dataset and start pre-processing\n",
    "./prepare-iwslt14.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to apply the second set of pre-processing, which binarizes the dataset based on the source and target language. Full information on this script [here](https://github.com/pytorch/fairseq/blob/master/preprocess.py).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(alignfile=None, cpu=False, criterion='cross_entropy', dataset_impl='cached', destdir='../data/iwslt14.tokenized.de-en', fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tbmf_wrapper=False, tensorboard_logdir='', testpref='../data/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, trainpref='../data/iwslt14.tokenized.de-en/train', user_dir=None, validpref='../data/iwslt14.tokenized.de-en/valid', workers=1)\n",
      "| [de] Dictionary: 8847 types\n",
      "| [de] ../data/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n",
      "| [de] Dictionary: 8847 types\n",
      "| [de] ../data/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n",
      "| [de] Dictionary: 8847 types\n",
      "| [de] ../data/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n",
      "| [en] Dictionary: 6631 types\n",
      "| [en] ../data/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n",
      "| [en] Dictionary: 6631 types\n",
      "| [en] ../data/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n",
      "| [en] Dictionary: 6631 types\n",
      "| [en] ../data/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n",
      "| Wrote preprocessed data to ../data/iwslt14.tokenized.de-en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq-git'...\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# First we download fairseq in order to have access to the scripts\n",
    "git clone https://github.com/pytorch/fairseq.git fairseq-git\n",
    "cd fairseq-git\n",
    "\n",
    "# Binarize the dataset:\n",
    "TEXT=../data/iwslt14.tokenized.de-en\n",
    "python preprocess.py --source-lang de --target-lang en \\\n",
    "  --trainpref $TEXT/train --validpref $TEXT/valid --testpref $TEXT/test \\\n",
    "  --destdir ../data/iwslt14.tokenized.de-en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is now all prepared for training on one of the FAIRSeq translation models. The next step is upload the data to Amazon S3 in order to make it available for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region =  sagemaker_session.boto_session.region_name\n",
    "account = sagemaker_session.boto_session.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-pytorch-fairseq/datasets/iwslt14'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sagemaker_session.upload_data(path='data/iwslt14.tokenized.de-en', bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to register a Docker image in Amazon SageMaker that will contain the FAIRSeq code and that will be pulled at training and inference time to perform the respective training of the model and the serving of the precitions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build FAIRSeq Translation task container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting from region us-east-1 and account 578276202366\n",
      "Login Succeeded\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  560.4MB\r",
      "\r\n",
      "Step 1/21 : FROM nvidia/cuda:9.0-cudnn7-devel-ubuntu16.04\n",
      " ---> 65dee97b9662\n",
      "Step 2/21 : ARG PYTHON_VERSION=3.6\n",
      " ---> Using cache\n",
      " ---> dbabb7c39cda\n",
      "Step 3/21 : RUN apt-get update && apt-get install -y --no-install-recommends          build-essential          cmake          nginx          jq          wget          git          curl          vim          ca-certificates          libjpeg-dev          libpng-dev &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> fcac7a7c9256\n",
      "Step 4/21 : RUN curl -o ~/miniconda.sh -O  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh  &&      chmod +x ~/miniconda.sh &&      ~/miniconda.sh -b -p /opt/conda &&      rm ~/miniconda.sh &&      /opt/conda/bin/conda install -y python=$PYTHON_VERSION numpy pyyaml scipy ipython mkl mkl-include cython typing &&      /opt/conda/bin/conda install -y -c pytorch pytorch &&      /opt/conda/bin/conda clean -ya\n",
      " ---> Using cache\n",
      " ---> 3955d29121a8\n",
      "Step 5/21 : ENV PATH /opt/conda/bin:$PATH\n",
      " ---> Using cache\n",
      " ---> 10cd55e717f1\n",
      "Step 6/21 : RUN pip install sagemaker flask gevent gunicorn --ignore-installed PyYAML\n",
      " ---> Using cache\n",
      " ---> 4cde555f1a3c\n",
      "Step 7/21 : RUN git clone https://github.com/pytorch/fairseq.git &&     cd fairseq &&     git checkout 672977c1bc3fd0d37c91ab0a2828c56bbd2b0769 &&     pip install -r requirements.txt &&     python setup.py build develop\n",
      " ---> Using cache\n",
      " ---> eb81e4d63fb9\n",
      "Step 8/21 : COPY lib/changehostname.c /\n",
      " ---> Using cache\n",
      " ---> 02bb26e661a5\n",
      "Step 9/21 : COPY lib/start_with_right_hostname.sh /usr/local/bin/start_with_right_hostname.sh\n",
      " ---> Using cache\n",
      " ---> b72762c72b96\n",
      "Step 10/21 : RUN chmod +x /usr/local/bin/start_with_right_hostname.sh\n",
      " ---> Using cache\n",
      " ---> 6e17abc67d1d\n",
      "Step 11/21 : RUN echo exit 0 > /usr/sbin/policy-rc.d\n",
      " ---> Using cache\n",
      " ---> 5ed856596f23\n",
      "Step 12/21 : RUN apt update\n",
      " ---> Using cache\n",
      " ---> 112e26543d65\n",
      "Step 13/21 : RUN apt-get install -y --no-install-recommends openssh-client openssh-server\n",
      " ---> Using cache\n",
      " ---> 8ed6d19f3d47\n",
      "Step 14/21 : RUN mkdir -p /var/run/sshd &&   sed 's@session\\s*required\\s*pam_loginuid.so@session optional pam_loginuid.so@g' -i /etc/pam.d/sshd\n",
      " ---> Using cache\n",
      " ---> a8bc8097fd3a\n",
      "Step 15/21 : RUN mkdir -p /root/.ssh/ &&   ssh-keygen -q -t rsa -N '' -f /root/.ssh/id_rsa &&   cp /root/.ssh/id_rsa.pub /root/.ssh/authorized_keys &&   printf \"Host *\\n  StrictHostKeyChecking no\\n\" >> /root/.ssh/config\n",
      " ---> Using cache\n",
      " ---> 257c38d03d7a\n",
      "Step 16/21 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> c25e17573464\n",
      "Step 17/21 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> 3dae781aee0c\n",
      "Step 18/21 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> b059ee0a5980\n",
      "Step 19/21 : COPY fairseq /opt/ml/code\n",
      " ---> d32650247d45\n",
      "Step 20/21 : WORKDIR /opt/ml/code\n",
      " ---> Running in 443149aa8aa0\n",
      "Removing intermediate container 443149aa8aa0\n",
      " ---> 27b7dba862e9\n",
      "Step 21/21 : ENTRYPOINT [\"bash\", \"-m\", \"start_with_right_hostname.sh\"]\n",
      " ---> Running in 5a584c1c119f\n",
      "Removing intermediate container 5a584c1c119f\n",
      " ---> cd460af6b059\n",
      "Successfully built cd460af6b059\n",
      "Successfully tagged pytorch-fairseq:latest\n",
      "The push refers to repository [578276202366.dkr.ecr.us-east-1.amazonaws.com/pytorch-fairseq]\n",
      "b1ac474030bd: Preparing\n",
      "916fa8fe8874: Preparing\n",
      "0707d29f8f1f: Preparing\n",
      "02f95ac1e589: Preparing\n",
      "e83c216f7b38: Preparing\n",
      "8ec56771257d: Preparing\n",
      "4154861bb629: Preparing\n",
      "f16d84a82e23: Preparing\n",
      "106b148cbd65: Preparing\n",
      "75b09a520510: Preparing\n",
      "29a5876fe213: Preparing\n",
      "4e6a5461d228: Preparing\n",
      "fb4ba4594f05: Preparing\n",
      "25a0eb3abf5c: Preparing\n",
      "f00a7198b4a5: Preparing\n",
      "9474b1166576: Preparing\n",
      "562561ff09c5: Preparing\n",
      "5efc208b2662: Preparing\n",
      "faffa9223884: Preparing\n",
      "4c54072a5034: Preparing\n",
      "49652298c779: Preparing\n",
      "e15278fcccca: Preparing\n",
      "739482a9723d: Preparing\n",
      "106b148cbd65: Waiting\n",
      "75b09a520510: Waiting\n",
      "29a5876fe213: Waiting\n",
      "4e6a5461d228: Waiting\n",
      "fb4ba4594f05: Waiting\n",
      "25a0eb3abf5c: Waiting\n",
      "f00a7198b4a5: Waiting\n",
      "9474b1166576: Waiting\n",
      "562561ff09c5: Waiting\n",
      "5efc208b2662: Waiting\n",
      "faffa9223884: Waiting\n",
      "4c54072a5034: Waiting\n",
      "49652298c779: Waiting\n",
      "e15278fcccca: Waiting\n",
      "739482a9723d: Waiting\n",
      "8ec56771257d: Waiting\n",
      "4154861bb629: Waiting\n",
      "f16d84a82e23: Waiting\n",
      "e83c216f7b38: Layer already exists\n",
      "916fa8fe8874: Layer already exists\n",
      "0707d29f8f1f: Layer already exists\n",
      "02f95ac1e589: Layer already exists\n",
      "8ec56771257d: Layer already exists\n",
      "f16d84a82e23: Layer already exists\n",
      "4154861bb629: Layer already exists\n",
      "106b148cbd65: Layer already exists\n",
      "75b09a520510: Layer already exists\n",
      "29a5876fe213: Layer already exists\n",
      "4e6a5461d228: Layer already exists\n",
      "fb4ba4594f05: Layer already exists\n",
      "25a0eb3abf5c: Layer already exists\n",
      "f00a7198b4a5: Layer already exists\n",
      "9474b1166576: Layer already exists\n",
      "5efc208b2662: Layer already exists\n",
      "562561ff09c5: Layer already exists\n",
      "faffa9223884: Layer already exists\n",
      "4c54072a5034: Layer already exists\n",
      "49652298c779: Layer already exists\n",
      "e15278fcccca: Layer already exists\n",
      "739482a9723d: Layer already exists\n",
      "b1ac474030bd: Pushed\n",
      "latest: digest: sha256:beb29783cffb10806f82c58afda09ae14231343a8f8340b60e4365dbc4a29771 size: 5144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "chmod +x create_container.sh \n",
    "\n",
    "./create_container.sh pytorch-fairseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FAIRSeq image has been pushed into Amazon ECR, the registry from which Amazon SageMaker will be able to pull that image and launch both training and prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Amazon SageMaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will set the hyper-parameters of the model we want to train. Here we are using the recommended ones from the [FAIRSeq example](https://github.com/pytorch/fairseq/tree/master/examples/translation#prepare-iwslt14sh). The full list of hyper-parameters available for use can be found [here](https://fairseq.readthedocs.io/en/latest/command_line_tools.html). Please note you can use dataset, training, and generation parameters. For the distributed backend, **gloo** is the only supported option and is set as default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"lr\": 0.25,    \n",
    "    \"clip-norm\": 0.1,\n",
    "    \"dropout\": 0.2,\n",
    "    \"max-tokens\": 4000,\n",
    "    \"criterion\": \"label_smoothed_cross_entropy\",\n",
    "    \"label-smoothing\": 0.1,\n",
    "    \"lr-scheduler\": \"fixed\",\n",
    "    \"force-anneal\": 200,\n",
    "    \"arch\": \"fconv_iwslt_de_en\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to define the Estimator, which will encapsulate all the required parameters needed for launching the training on Amazon SageMaker. \n",
    "\n",
    "For training, the FAIRSeq toolkit recommends to train on GPU instances, such as the `ml.p3` instance family [available in Amazon SageMaker](https://aws.amazon.com/sagemaker/pricing/instance-types/). In this example, we are training on 2 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "algorithm_name = \"pytorch-fairseq\"\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, algorithm_name)\n",
    "\n",
    "estimator = Estimator(image,\n",
    "                     role,\n",
    "                     train_instance_count=2,\n",
    "                     train_instance_type='ml.p3.8xlarge',\n",
    "                     train_volume_size=100, \n",
    "                     output_path='s3://{}/output'.format(bucket),\n",
    "                     hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call to fit will launch the training job and regularly report on the different performance metrics related to the training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-28 22:06:40 Starting - Starting the training job...\n",
      "2019-06-28 22:06:55 Starting - Launching requested ML instances......\n",
      "2019-06-28 22:07:57 Starting - Preparing the instances for training......\n",
      "2019-06-28 22:09:08 Downloading - Downloading input data\n",
      "2019-06-28 22:09:08 Training - Downloading the training image............\n",
      "2019-06-28 22:11:02 Training - Training image download completed. Training in progress.\n",
      "\u001b[32mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[32mbash: no job control in this shell\u001b[0m\n",
      "\u001b[32mStarting the training.\u001b[0m\n",
      "\u001b[32m{'force-anneal': '200', 'criterion': 'label_smoothed_cross_entropy', 'lr': '0.25', 'dropout': '0.2', 'label-smoothing': '0.1', 'clip-norm': '0.1', 'lr-scheduler': 'fixed', 'max-tokens': '4000', 'arch': 'fconv_iwslt_de_en'}\u001b[0m\n",
      "\u001b[32m['--force-anneal', '200', '--criterion', 'label_smoothed_cross_entropy', '--lr', '0.25', '--dropout', '0.2', '--label-smoothing', '0.1', '--clip-norm', '0.1', '--lr-scheduler', 'fixed', '--max-tokens', '4000', '--arch', 'fconv_iwslt_de_en']\u001b[0m\n",
      "\u001b[32mNamespace(arch='fconv_iwslt_de_en', beam=5, bucket_cap_mb=150, buffer_size=0, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', data=['/opt/ml/input/data/training'], ddp_backend='c10d', decoder_attention='True', decoder_embed_dim=256, decoder_embed_path=None, decoder_layers='[(256, 3)] * 3', decoder_out_embed_dim=256, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=4, diverse_beam_groups=1, diverse_beam_strength=0.5, dropout=0.2, encoder_embed_dim=256, encoder_embed_path=None, encoder_layers='[(256, 3)] * 4', fix_batches_to_gpus=False, force_anneal=200, fp16=False, fp16_init_scale=128, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_len_a=0, max_len_b=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_update=0, min_len=1, min_loss_scale=0.0001, min_lr=1e-05, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, optimizer='nag', optimizer_overrides='{}', path=None, prefix_size=0, print_alignment=False, quiet=False, raw_text=False, remove_bpe=None, replace_unk=None, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='/opt/ml/model', save_interval=1, save_interval_updates=0, score_reference=False, seed=1, sentence_avg=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], upsample_primary=1, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\u001b[0m\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31m{'force-anneal': '200', 'criterion': 'label_smoothed_cross_entropy', 'lr': '0.25', 'dropout': '0.2', 'label-smoothing': '0.1', 'clip-norm': '0.1', 'lr-scheduler': 'fixed', 'max-tokens': '4000', 'arch': 'fconv_iwslt_de_en'}\u001b[0m\n",
      "\u001b[31m['--force-anneal', '200', '--criterion', 'label_smoothed_cross_entropy', '--lr', '0.25', '--dropout', '0.2', '--label-smoothing', '0.1', '--clip-norm', '0.1', '--lr-scheduler', 'fixed', '--max-tokens', '4000', '--arch', 'fconv_iwslt_de_en']\u001b[0m\n",
      "\u001b[31mNamespace(arch='fconv_iwslt_de_en', beam=5, bucket_cap_mb=150, buffer_size=0, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', data=['/opt/ml/input/data/training'], ddp_backend='c10d', decoder_attention='True', decoder_embed_dim=256, decoder_embed_path=None, decoder_layers='[(256, 3)] * 3', decoder_out_embed_dim=256, device_id=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, distributed_rank=0, distributed_world_size=4, diverse_beam_groups=1, diverse_beam_strength=0.5, dropout=0.2, encoder_embed_dim=256, encoder_embed_path=None, encoder_layers='[(256, 3)] * 4', fix_batches_to_gpus=False, force_anneal=200, fp16=False, fp16_init_scale=128, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_len_a=0, max_len_b=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_update=0, min_len=1, min_loss_scale=0.0001, min_lr=1e-05, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, optimizer='nag', optimizer_overrides='{}', path=None, prefix_size=0, print_alignment=False, quiet=False, raw_text=False, remove_bpe=None, replace_unk=None, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='/opt/ml/model', save_interval=1, save_interval_updates=0, score_reference=False, seed=1, sentence_avg=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], upsample_primary=1, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:03,162 distributed_train INFO     hosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:03,199 distributed_train INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:03,199 distributed_train INFO     Connection failed with exception: \n",
      " [Errno -2] Name or service not known\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:03,246 distributed_train INFO     Cannot connect to host algo-2\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:03,246 distributed_train INFO     Connection failed with exception: \n",
      " [Errno -2] Name or service not known\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:02,931 distributed_train INFO     hosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:03,002 distributed_train INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:03,002 distributed_train INFO     Connection failed with exception: \n",
      " [Errno -2] Name or service not known\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:03,084 distributed_train INFO     Cannot connect to host algo-2\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:03,084 distributed_train INFO     Connection failed with exception: \n",
      " [Errno -2] Name or service not known\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:04,247 distributed_train INFO     hosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:04,252 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.2p2)\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:04,347 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:04,347 distributed_train INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:04,086 distributed_train INFO     hosts that aren't SSHable yet: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:04,091 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.2p2)\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:04,196 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:04,196 distributed_train INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:05,348 distributed_train INFO     hosts that aren't SSHable yet: ['algo-2']\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:05,353 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.2p2)\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:05,446 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[31m2019-06-28 22:11:05,446 distributed_train INFO     Can connect to host algo-2\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:05,197 distributed_train INFO     hosts that aren't SSHable yet: ['algo-2']\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:05,203 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.2p2)\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:05,279 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[32m2019-06-28 22:11:05,279 distributed_train INFO     Can connect to host algo-2\u001b[0m\n",
      "\u001b[31m| distributed init (rank 3): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[31m| distributed init (rank 0): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[31m| distributed init (rank 2): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[31m| distributed init (rank 1): tcp://algo-1:1112\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m| distributed init (rank 7): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[32m| distributed init (rank 4): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[32m| distributed init (rank 5): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[32m| distributed init (rank 6): tcp://algo-1:1112\u001b[0m\n",
      "\u001b[31m| initialized host algo-1 as rank 0\u001b[0m\n",
      "\u001b[31mNamespace(arch='fconv_iwslt_de_en', beam=5, bucket_cap_mb=150, buffer_size=0, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', data=['/opt/ml/input/data/training'], ddp_backend='c10d', decoder_attention='True', decoder_embed_dim=256, decoder_embed_path=None, decoder_layers='[(256, 3)] * 3', decoder_out_embed_dim=256, device_id=0, distributed_backend='gloo', distributed_init_method='tcp://algo-1:1112', distributed_port=-1, distributed_rank=0, distributed_world_size=8, diverse_beam_groups=1, diverse_beam_strength=0.5, dropout=0.2, encoder_embed_dim=256, encoder_embed_path=None, encoder_layers='[(256, 3)] * 4', fix_batches_to_gpus=False, force_anneal=200, fp16=False, fp16_init_scale=128, keep_interval_updates=-1, label_smoothing=0.1, left_pad_source='True', left_pad_target='False', lenpen=1, log_format=None, log_interval=1000, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_len_a=0, max_len_b=200, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_update=0, min_len=1, min_loss_scale=0.0001, min_lr=1e-05, model_overrides='{}', momentum=0.99, nbest=1, no_beamable_mm=False, no_early_stop=False, no_epoch_checkpoints=False, no_progress_bar=False, no_save=False, optimizer='nag', optimizer_overrides='{}', path=None, prefix_size=0, print_alignment=False, quiet=False, raw_text=False, remove_bpe=None, replace_unk=None, reset_lr_scheduler=False, reset_optimizer=False, restore_file='checkpoint_last.pt', sampling=False, sampling_temperature=1, sampling_topk=-1, save_dir='/opt/ml/model', save_interval=1, save_interval_updates=0, score_reference=False, seed=1, sentence_avg=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', train_subset='train', unkpen=0, unnormalized=False, update_freq=[1], upsample_primary=1, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\u001b[0m\n",
      "\u001b[31m| [de] dictionary: 8848 types\u001b[0m\n",
      "\u001b[31m| [en] dictionary: 6632 types\u001b[0m\n",
      "\u001b[31m| /opt/ml/input/data/training train 160239 examples\u001b[0m\n",
      "\u001b[31m| /opt/ml/input/data/training valid 7283 examples\u001b[0m\n",
      "\u001b[31m| model fconv_iwslt_de_en, criterion LabelSmoothedCrossEntropyCriterion\u001b[0m\n",
      "\u001b[31m| num. model params: 9618384\u001b[0m\n",
      "\u001b[31m| training on 8 GPUs\u001b[0m\n",
      "\u001b[31m| max tokens per GPU = 4000 and max sentences per GPU = None\u001b[0m\n",
      "\u001b[31m| NOTICE: your device may support faster training with --fp16\u001b[0m\n",
      "\u001b[31m| epoch 001 | loss 10.148 | nll_loss 9.703 | ppl 833.61 | wps 192955 | ups 6.4 | wpb 27811 | bsz 1128 | num_updates 142 | lr 0.25 | gnorm 0.849 | clip 100% | oom 0 | wall 22 | train_wall 18\u001b[0m\n",
      "\u001b[31m| epoch 001 | valid on 'valid' subset | valid_loss 9.10096 | valid_nll_loss 8.50878 | valid_ppl 364.25 | num_updates 142\u001b[0m\n",
      "\u001b[31m| epoch 002 | loss 8.690 | nll_loss 8.029 | ppl 261.18 | wps 195522 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 284 | lr 0.25 | gnorm 0.160 | clip 96% | oom 0 | wall 43 | train_wall 36\u001b[0m\n",
      "\u001b[31m| epoch 002 | valid on 'valid' subset | valid_loss 8.19909 | valid_nll_loss 7.47326 | valid_ppl 177.69 | num_updates 284 | best 8.19909\u001b[0m\n",
      "\u001b[31m| epoch 003 | loss 8.009 | nll_loss 7.238 | ppl 150.91 | wps 197191 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 426 | lr 0.25 | gnorm 0.131 | clip 92% | oom 0 | wall 64 | train_wall 53\u001b[0m\n",
      "\u001b[31m| epoch 003 | valid on 'valid' subset | valid_loss 7.57091 | valid_nll_loss 6.74735 | valid_ppl 107.44 | num_updates 426 | best 7.57091\u001b[0m\n",
      "\u001b[31m| epoch 004 | loss 7.453 | nll_loss 6.584 | ppl 95.97 | wps 196629 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 568 | lr 0.25 | gnorm 0.127 | clip 93% | oom 0 | wall 85 | train_wall 70\u001b[0m\n",
      "\u001b[31m| epoch 004 | valid on 'valid' subset | valid_loss 7.01927 | valid_nll_loss 6.10043 | valid_ppl 68.61 | num_updates 568 | best 7.01927\u001b[0m\n",
      "\u001b[31m| epoch 005 | loss 6.983 | nll_loss 6.027 | ppl 65.21 | wps 195855 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 710 | lr 0.25 | gnorm 0.133 | clip 100% | oom 0 | wall 106 | train_wall 88\u001b[0m\n",
      "\u001b[31m| epoch 005 | valid on 'valid' subset | valid_loss 6.58963 | valid_nll_loss 5.59247 | valid_ppl 48.25 | num_updates 710 | best 6.58963\u001b[0m\n",
      "\u001b[31m| epoch 006 | loss 6.603 | nll_loss 5.573 | ppl 47.61 | wps 195774 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 852 | lr 0.25 | gnorm 0.142 | clip 100% | oom 0 | wall 127 | train_wall 105\u001b[0m\n",
      "\u001b[31m| epoch 006 | valid on 'valid' subset | valid_loss 6.22325 | valid_nll_loss 5.16689 | valid_ppl 35.92 | num_updates 852 | best 6.22325\u001b[0m\n",
      "\u001b[31m| epoch 007 | loss 6.281 | nll_loss 5.188 | ppl 36.46 | wps 194925 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 994 | lr 0.25 | gnorm 0.150 | clip 100% | oom 0 | wall 148 | train_wall 123\u001b[0m\n",
      "\u001b[31m| epoch 007 | valid on 'valid' subset | valid_loss 5.90517 | valid_nll_loss 4.77543 | valid_ppl 27.39 | num_updates 994 | best 5.90517\u001b[0m\n",
      "\u001b[31m| epoch 008 | loss 6.013 | nll_loss 4.866 | ppl 29.17 | wps 195053 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 1136 | lr 0.25 | gnorm 0.152 | clip 100% | oom 0 | wall 169 | train_wall 141\u001b[0m\n",
      "\u001b[31m| epoch 008 | valid on 'valid' subset | valid_loss 5.66439 | valid_nll_loss 4.48589 | valid_ppl 22.41 | num_updates 1136 | best 5.66439\u001b[0m\n",
      "\u001b[31m| epoch 009 | loss 5.797 | nll_loss 4.610 | ppl 24.42 | wps 194923 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 1278 | lr 0.25 | gnorm 0.162 | clip 100% | oom 0 | wall 190 | train_wall 158\u001b[0m\n",
      "\u001b[31m| epoch 009 | valid on 'valid' subset | valid_loss 5.47549 | valid_nll_loss 4.25451 | valid_ppl 19.09 | num_updates 1278 | best 5.47549\u001b[0m\n",
      "\u001b[31m| epoch 010 | loss 5.627 | nll_loss 4.409 | ppl 21.25 | wps 196225 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 1420 | lr 0.25 | gnorm 0.160 | clip 100% | oom 0 | wall 210 | train_wall 176\u001b[0m\n",
      "\u001b[31m| epoch 010 | valid on 'valid' subset | valid_loss 5.3266 | valid_nll_loss 4.08759 | valid_ppl 17.00 | num_updates 1420 | best 5.3266\u001b[0m\n",
      "\u001b[31m| epoch 011 | loss 5.486 | nll_loss 4.243 | ppl 18.94 | wps 195938 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 1562 | lr 0.25 | gnorm 0.157 | clip 100% | oom 0 | wall 231 | train_wall 194\u001b[0m\n",
      "\u001b[31m| epoch 011 | valid on 'valid' subset | valid_loss 5.21034 | valid_nll_loss 3.95218 | valid_ppl 15.48 | num_updates 1562 | best 5.21034\u001b[0m\n",
      "\u001b[31m| epoch 012 | loss 5.369 | nll_loss 4.108 | ppl 17.24 | wps 194173 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 1704 | lr 0.25 | gnorm 0.155 | clip 100% | oom 0 | wall 252 | train_wall 211\u001b[0m\n",
      "\u001b[31m| epoch 012 | valid on 'valid' subset | valid_loss 5.11865 | valid_nll_loss 3.8334 | valid_ppl 14.26 | num_updates 1704 | best 5.11865\u001b[0m\n",
      "\u001b[31m| epoch 013 | loss 5.272 | nll_loss 3.995 | ppl 15.95 | wps 196498 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 1846 | lr 0.25 | gnorm 0.155 | clip 100% | oom 0 | wall 273 | train_wall 229\u001b[0m\n",
      "\u001b[31m| epoch 013 | valid on 'valid' subset | valid_loss 5.0385 | valid_nll_loss 3.74328 | valid_ppl 13.39 | num_updates 1846 | best 5.0385\u001b[0m\n",
      "\u001b[31m| epoch 014 | loss 5.188 | nll_loss 3.898 | ppl 14.91 | wps 196174 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 1988 | lr 0.25 | gnorm 0.154 | clip 100% | oom 0 | wall 294 | train_wall 246\u001b[0m\n",
      "\u001b[31m| epoch 014 | valid on 'valid' subset | valid_loss 4.97082 | valid_nll_loss 3.66124 | valid_ppl 12.65 | num_updates 1988 | best 4.97082\u001b[0m\n",
      "\u001b[31m| epoch 015 | loss 5.115 | nll_loss 3.813 | ppl 14.05 | wps 194644 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 2130 | lr 0.25 | gnorm 0.156 | clip 100% | oom 0 | wall 315 | train_wall 264\u001b[0m\n",
      "\u001b[31m| epoch 015 | valid on 'valid' subset | valid_loss 4.90601 | valid_nll_loss 3.59391 | valid_ppl 12.07 | num_updates 2130 | best 4.90601\u001b[0m\n",
      "\u001b[31m| epoch 016 | loss 5.052 | nll_loss 3.739 | ppl 13.36 | wps 195676 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 2272 | lr 0.25 | gnorm 0.154 | clip 100% | oom 0 | wall 336 | train_wall 281\u001b[0m\n",
      "\u001b[31m| epoch 016 | valid on 'valid' subset | valid_loss 4.85846 | valid_nll_loss 3.53473 | valid_ppl 11.59 | num_updates 2272 | best 4.85846\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 017 | loss 4.995 | nll_loss 3.675 | ppl 12.77 | wps 192844 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 2414 | lr 0.25 | gnorm 0.156 | clip 100% | oom 0 | wall 357 | train_wall 299\u001b[0m\n",
      "\u001b[31m| epoch 017 | valid on 'valid' subset | valid_loss 4.81364 | valid_nll_loss 3.48223 | valid_ppl 11.18 | num_updates 2414 | best 4.81364\u001b[0m\n",
      "\u001b[31m| epoch 018 | loss 4.945 | nll_loss 3.618 | ppl 12.27 | wps 196139 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 2556 | lr 0.25 | gnorm 0.155 | clip 100% | oom 0 | wall 378 | train_wall 317\u001b[0m\n",
      "\u001b[31m| epoch 018 | valid on 'valid' subset | valid_loss 4.77616 | valid_nll_loss 3.44514 | valid_ppl 10.89 | num_updates 2556 | best 4.77616\u001b[0m\n",
      "\u001b[31m| epoch 019 | loss 4.899 | nll_loss 3.564 | ppl 11.83 | wps 195428 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 2698 | lr 0.25 | gnorm 0.153 | clip 100% | oom 0 | wall 399 | train_wall 334\u001b[0m\n",
      "\u001b[31m| epoch 019 | valid on 'valid' subset | valid_loss 4.74052 | valid_nll_loss 3.39411 | valid_ppl 10.51 | num_updates 2698 | best 4.74052\u001b[0m\n",
      "\u001b[31m| epoch 020 | loss 4.858 | nll_loss 3.517 | ppl 11.45 | wps 194490 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 2840 | lr 0.25 | gnorm 0.153 | clip 100% | oom 0 | wall 420 | train_wall 352\u001b[0m\n",
      "\u001b[31m| epoch 020 | valid on 'valid' subset | valid_loss 4.70805 | valid_nll_loss 3.35147 | valid_ppl 10.21 | num_updates 2840 | best 4.70805\u001b[0m\n",
      "\u001b[31m| epoch 021 | loss 4.820 | nll_loss 3.473 | ppl 11.10 | wps 195914 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 2982 | lr 0.25 | gnorm 0.150 | clip 100% | oom 0 | wall 441 | train_wall 370\u001b[0m\n",
      "\u001b[31m| epoch 021 | valid on 'valid' subset | valid_loss 4.68376 | valid_nll_loss 3.32359 | valid_ppl 10.01 | num_updates 2982 | best 4.68376\u001b[0m\n",
      "\u001b[31m| epoch 022 | loss 4.786 | nll_loss 3.435 | ppl 10.81 | wps 197617 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 3124 | lr 0.25 | gnorm 0.151 | clip 100% | oom 0 | wall 462 | train_wall 387\u001b[0m\n",
      "\u001b[31m| epoch 022 | valid on 'valid' subset | valid_loss 4.65355 | valid_nll_loss 3.29717 | valid_ppl 9.83 | num_updates 3124 | best 4.65355\u001b[0m\n",
      "\u001b[31m| epoch 023 | loss 4.754 | nll_loss 3.398 | ppl 10.54 | wps 192427 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 3266 | lr 0.25 | gnorm 0.149 | clip 100% | oom 0 | wall 483 | train_wall 405\u001b[0m\n",
      "\u001b[31m| epoch 023 | valid on 'valid' subset | valid_loss 4.6304 | valid_nll_loss 3.26589 | valid_ppl 9.62 | num_updates 3266 | best 4.6304\u001b[0m\n",
      "\u001b[31m| epoch 024 | loss 4.726 | nll_loss 3.365 | ppl 10.30 | wps 199217 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 3408 | lr 0.25 | gnorm 0.149 | clip 100% | oom 0 | wall 504 | train_wall 422\u001b[0m\n",
      "\u001b[31m| epoch 024 | valid on 'valid' subset | valid_loss 4.60901 | valid_nll_loss 3.23966 | valid_ppl 9.45 | num_updates 3408 | best 4.60901\u001b[0m\n",
      "\u001b[31m| epoch 025 | loss 4.697 | nll_loss 3.332 | ppl 10.07 | wps 196488 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 3550 | lr 0.25 | gnorm 0.147 | clip 100% | oom 0 | wall 524 | train_wall 440\u001b[0m\n",
      "\u001b[31m| epoch 025 | valid on 'valid' subset | valid_loss 4.59343 | valid_nll_loss 3.21941 | valid_ppl 9.31 | num_updates 3550 | best 4.59343\u001b[0m\n",
      "\u001b[31m| epoch 026 | loss 4.672 | nll_loss 3.302 | ppl 9.87 | wps 193169 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 3692 | lr 0.25 | gnorm 0.148 | clip 100% | oom 0 | wall 546 | train_wall 458\u001b[0m\n",
      "\u001b[31m| epoch 026 | valid on 'valid' subset | valid_loss 4.57461 | valid_nll_loss 3.19398 | valid_ppl 9.15 | num_updates 3692 | best 4.57461\u001b[0m\n",
      "\u001b[31m| epoch 027 | loss 4.647 | nll_loss 3.274 | ppl 9.67 | wps 194905 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 3834 | lr 0.25 | gnorm 0.146 | clip 100% | oom 0 | wall 567 | train_wall 475\u001b[0m\n",
      "\u001b[31m| epoch 027 | valid on 'valid' subset | valid_loss 4.55692 | valid_nll_loss 3.17911 | valid_ppl 9.06 | num_updates 3834 | best 4.55692\u001b[0m\n",
      "\u001b[31m| epoch 028 | loss 4.623 | nll_loss 3.247 | ppl 9.49 | wps 196518 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 3976 | lr 0.25 | gnorm 0.147 | clip 100% | oom 0 | wall 588 | train_wall 493\u001b[0m\n",
      "\u001b[31m| epoch 028 | valid on 'valid' subset | valid_loss 4.53621 | valid_nll_loss 3.16094 | valid_ppl 8.94 | num_updates 3976 | best 4.53621\u001b[0m\n",
      "\u001b[31m| epoch 029 | loss 4.603 | nll_loss 3.223 | ppl 9.34 | wps 194987 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 4118 | lr 0.25 | gnorm 0.149 | clip 100% | oom 0 | wall 609 | train_wall 510\u001b[0m\n",
      "\u001b[31m| epoch 029 | valid on 'valid' subset | valid_loss 4.52859 | valid_nll_loss 3.14409 | valid_ppl 8.84 | num_updates 4118 | best 4.52859\u001b[0m\n",
      "\u001b[31m| epoch 030 | loss 4.583 | nll_loss 3.201 | ppl 9.19 | wps 195494 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 4260 | lr 0.25 | gnorm 0.146 | clip 100% | oom 0 | wall 630 | train_wall 528\u001b[0m\n",
      "\u001b[31m| epoch 030 | valid on 'valid' subset | valid_loss 4.51627 | valid_nll_loss 3.12014 | valid_ppl 8.69 | num_updates 4260 | best 4.51627\u001b[0m\n",
      "\u001b[31m| epoch 031 | loss 4.562 | nll_loss 3.177 | ppl 9.04 | wps 197025 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 4402 | lr 0.25 | gnorm 0.145 | clip 100% | oom 0 | wall 651 | train_wall 545\u001b[0m\n",
      "\u001b[31m| epoch 031 | valid on 'valid' subset | valid_loss 4.49772 | valid_nll_loss 3.10921 | valid_ppl 8.63 | num_updates 4402 | best 4.49772\u001b[0m\n",
      "\u001b[31m| epoch 032 | loss 4.546 | nll_loss 3.159 | ppl 8.93 | wps 195654 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 4544 | lr 0.25 | gnorm 0.145 | clip 100% | oom 0 | wall 671 | train_wall 563\u001b[0m\n",
      "\u001b[31m| epoch 032 | valid on 'valid' subset | valid_loss 4.48884 | valid_nll_loss 3.09782 | valid_ppl 8.56 | num_updates 4544 | best 4.48884\u001b[0m\n",
      "\u001b[31m| epoch 033 | loss 4.529 | nll_loss 3.139 | ppl 8.81 | wps 195980 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 4686 | lr 0.25 | gnorm 0.145 | clip 100% | oom 0 | wall 692 | train_wall 580\u001b[0m\n",
      "\u001b[31m| epoch 033 | valid on 'valid' subset | valid_loss 4.47525 | valid_nll_loss 3.08287 | valid_ppl 8.47 | num_updates 4686 | best 4.47525\u001b[0m\n",
      "\u001b[31m| epoch 034 | loss 4.512 | nll_loss 3.119 | ppl 8.69 | wps 195196 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 4828 | lr 0.25 | gnorm 0.143 | clip 100% | oom 0 | wall 713 | train_wall 598\u001b[0m\n",
      "\u001b[31m| epoch 034 | valid on 'valid' subset | valid_loss 4.4678 | valid_nll_loss 3.07564 | valid_ppl 8.43 | num_updates 4828 | best 4.4678\u001b[0m\n",
      "\u001b[31m| epoch 035 | loss 4.497 | nll_loss 3.101 | ppl 8.58 | wps 194677 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 4970 | lr 0.25 | gnorm 0.144 | clip 100% | oom 0 | wall 734 | train_wall 615\u001b[0m\n",
      "\u001b[31m| epoch 035 | valid on 'valid' subset | valid_loss 4.45637 | valid_nll_loss 3.05568 | valid_ppl 8.31 | num_updates 4970 | best 4.45637\u001b[0m\n",
      "\u001b[31m| epoch 036 | loss 4.481 | nll_loss 3.083 | ppl 8.48 | wps 196615 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 5112 | lr 0.25 | gnorm 0.143 | clip 100% | oom 0 | wall 755 | train_wall 633\u001b[0m\n",
      "\u001b[31m| epoch 036 | valid on 'valid' subset | valid_loss 4.44468 | valid_nll_loss 3.0466 | valid_ppl 8.26 | num_updates 5112 | best 4.44468\u001b[0m\n",
      "\u001b[31m| epoch 037 | loss 4.467 | nll_loss 3.067 | ppl 8.38 | wps 195777 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 5254 | lr 0.25 | gnorm 0.142 | clip 100% | oom 0 | wall 776 | train_wall 650\u001b[0m\n",
      "\u001b[31m| epoch 037 | valid on 'valid' subset | valid_loss 4.43727 | valid_nll_loss 3.04542 | valid_ppl 8.26 | num_updates 5254 | best 4.43727\u001b[0m\n",
      "\u001b[31m| epoch 038 | loss 4.455 | nll_loss 3.054 | ppl 8.30 | wps 195474 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 5396 | lr 0.25 | gnorm 0.147 | clip 100% | oom 0 | wall 797 | train_wall 668\u001b[0m\n",
      "\u001b[31m| epoch 038 | valid on 'valid' subset | valid_loss 4.42549 | valid_nll_loss 3.02574 | valid_ppl 8.14 | num_updates 5396 | best 4.42549\u001b[0m\n",
      "\u001b[31m| epoch 039 | loss 4.440 | nll_loss 3.036 | ppl 8.20 | wps 194653 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 5538 | lr 0.25 | gnorm 0.142 | clip 100% | oom 0 | wall 818 | train_wall 686\u001b[0m\n",
      "\u001b[31m| epoch 039 | valid on 'valid' subset | valid_loss 4.41798 | valid_nll_loss 3.02364 | valid_ppl 8.13 | num_updates 5538 | best 4.41798\u001b[0m\n",
      "\u001b[31m| epoch 040 | loss 4.429 | nll_loss 3.024 | ppl 8.14 | wps 197604 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 5680 | lr 0.25 | gnorm 0.142 | clip 100% | oom 0 | wall 839 | train_wall 703\u001b[0m\n",
      "\u001b[31m| epoch 040 | valid on 'valid' subset | valid_loss 4.41927 | valid_nll_loss 3.00669 | valid_ppl 8.04 | num_updates 5680 | best 4.41798\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 041 | loss 4.417 | nll_loss 3.009 | ppl 8.05 | wps 193276 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 5822 | lr 0.25 | gnorm 0.143 | clip 100% | oom 0 | wall 860 | train_wall 721\u001b[0m\n",
      "\u001b[31m| epoch 041 | valid on 'valid' subset | valid_loss 4.40194 | valid_nll_loss 2.99931 | valid_ppl 8.00 | num_updates 5822 | best 4.40194\u001b[0m\n",
      "\u001b[31m| epoch 042 | loss 4.405 | nll_loss 2.996 | ppl 7.98 | wps 197481 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 5964 | lr 0.25 | gnorm 0.140 | clip 100% | oom 0 | wall 881 | train_wall 738\u001b[0m\n",
      "\u001b[31m| epoch 042 | valid on 'valid' subset | valid_loss 4.40072 | valid_nll_loss 2.98311 | valid_ppl 7.91 | num_updates 5964 | best 4.40072\u001b[0m\n",
      "\u001b[31m| epoch 043 | loss 4.394 | nll_loss 2.983 | ppl 7.90 | wps 195480 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 6106 | lr 0.25 | gnorm 0.141 | clip 100% | oom 0 | wall 902 | train_wall 756\u001b[0m\n",
      "\u001b[31m| epoch 043 | valid on 'valid' subset | valid_loss 4.39715 | valid_nll_loss 2.97854 | valid_ppl 7.88 | num_updates 6106 | best 4.39715\u001b[0m\n",
      "\u001b[31m| epoch 044 | loss 4.384 | nll_loss 2.971 | ppl 7.84 | wps 195977 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 6248 | lr 0.25 | gnorm 0.140 | clip 100% | oom 0 | wall 923 | train_wall 773\u001b[0m\n",
      "\u001b[31m| epoch 044 | valid on 'valid' subset | valid_loss 4.38665 | valid_nll_loss 2.9748 | valid_ppl 7.86 | num_updates 6248 | best 4.38665\u001b[0m\n",
      "\u001b[31m| epoch 045 | loss 4.373 | nll_loss 2.958 | ppl 7.77 | wps 198325 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 6390 | lr 0.25 | gnorm 0.141 | clip 100% | oom 0 | wall 943 | train_wall 790\u001b[0m\n",
      "\u001b[31m| epoch 045 | valid on 'valid' subset | valid_loss 4.37852 | valid_nll_loss 2.96328 | valid_ppl 7.80 | num_updates 6390 | best 4.37852\u001b[0m\n",
      "\u001b[31m| epoch 046 | loss 4.362 | nll_loss 2.946 | ppl 7.71 | wps 196411 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 6532 | lr 0.25 | gnorm 0.138 | clip 100% | oom 0 | wall 964 | train_wall 808\u001b[0m\n",
      "\u001b[31m| epoch 046 | valid on 'valid' subset | valid_loss 4.37151 | valid_nll_loss 2.96049 | valid_ppl 7.78 | num_updates 6532 | best 4.37151\u001b[0m\n",
      "\u001b[31m| epoch 047 | loss 4.354 | nll_loss 2.937 | ppl 7.66 | wps 195160 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 6674 | lr 0.25 | gnorm 0.139 | clip 100% | oom 0 | wall 985 | train_wall 826\u001b[0m\n",
      "\u001b[31m| epoch 047 | valid on 'valid' subset | valid_loss 4.36919 | valid_nll_loss 2.95223 | valid_ppl 7.74 | num_updates 6674 | best 4.36919\u001b[0m\n",
      "\u001b[31m| epoch 048 | loss 4.345 | nll_loss 2.926 | ppl 7.60 | wps 193940 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 6816 | lr 0.25 | gnorm 0.139 | clip 100% | oom 0 | wall 1006 | train_wall 843\u001b[0m\n",
      "\u001b[31m| epoch 048 | valid on 'valid' subset | valid_loss 4.36561 | valid_nll_loss 2.94799 | valid_ppl 7.72 | num_updates 6816 | best 4.36561\u001b[0m\n",
      "\u001b[31m| epoch 049 | loss 4.337 | nll_loss 2.917 | ppl 7.55 | wps 195499 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 6958 | lr 0.25 | gnorm 0.137 | clip 100% | oom 0 | wall 1027 | train_wall 861\u001b[0m\n",
      "\u001b[31m| epoch 049 | valid on 'valid' subset | valid_loss 4.36009 | valid_nll_loss 2.94161 | valid_ppl 7.68 | num_updates 6958 | best 4.36009\u001b[0m\n",
      "\u001b[31m| epoch 050 | loss 4.326 | nll_loss 2.904 | ppl 7.48 | wps 196209 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 7100 | lr 0.25 | gnorm 0.137 | clip 100% | oom 0 | wall 1048 | train_wall 878\u001b[0m\n",
      "\u001b[31m| epoch 050 | valid on 'valid' subset | valid_loss 4.36032 | valid_nll_loss 2.93084 | valid_ppl 7.63 | num_updates 7100 | best 4.36009\u001b[0m\n",
      "\u001b[31m| epoch 051 | loss 4.318 | nll_loss 2.895 | ppl 7.44 | wps 196835 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 7242 | lr 0.25 | gnorm 0.138 | clip 100% | oom 0 | wall 1069 | train_wall 896\u001b[0m\n",
      "\u001b[31m| epoch 051 | valid on 'valid' subset | valid_loss 4.35122 | valid_nll_loss 2.92487 | valid_ppl 7.59 | num_updates 7242 | best 4.35122\u001b[0m\n",
      "\u001b[31m| epoch 052 | loss 4.310 | nll_loss 2.885 | ppl 7.39 | wps 196044 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 7384 | lr 0.25 | gnorm 0.139 | clip 100% | oom 0 | wall 1090 | train_wall 914\u001b[0m\n",
      "\u001b[31m| epoch 052 | valid on 'valid' subset | valid_loss 4.3419 | valid_nll_loss 2.92064 | valid_ppl 7.57 | num_updates 7384 | best 4.3419\u001b[0m\n",
      "\u001b[31m| epoch 053 | loss 4.302 | nll_loss 2.877 | ppl 7.35 | wps 197735 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 7526 | lr 0.25 | gnorm 0.138 | clip 100% | oom 0 | wall 1110 | train_wall 931\u001b[0m\n",
      "\u001b[31m| epoch 053 | valid on 'valid' subset | valid_loss 4.35329 | valid_nll_loss 2.92253 | valid_ppl 7.58 | num_updates 7526 | best 4.3419\u001b[0m\n",
      "\u001b[31m| epoch 054 | loss 4.294 | nll_loss 2.868 | ppl 7.30 | wps 197333 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 7668 | lr 0.25 | gnorm 0.138 | clip 100% | oom 0 | wall 1131 | train_wall 948\u001b[0m\n",
      "\u001b[31m| epoch 054 | valid on 'valid' subset | valid_loss 4.33741 | valid_nll_loss 2.90941 | valid_ppl 7.51 | num_updates 7668 | best 4.33741\u001b[0m\n",
      "\u001b[31m| epoch 055 | loss 4.287 | nll_loss 2.859 | ppl 7.26 | wps 196366 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 7810 | lr 0.25 | gnorm 0.137 | clip 100% | oom 0 | wall 1152 | train_wall 966\u001b[0m\n",
      "\u001b[31m| epoch 055 | valid on 'valid' subset | valid_loss 4.33349 | valid_nll_loss 2.90385 | valid_ppl 7.48 | num_updates 7810 | best 4.33349\u001b[0m\n",
      "\u001b[31m| epoch 056 | loss 4.278 | nll_loss 2.850 | ppl 7.21 | wps 196672 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 7952 | lr 0.25 | gnorm 0.136 | clip 100% | oom 0 | wall 1173 | train_wall 983\u001b[0m\n",
      "\u001b[31m| epoch 056 | valid on 'valid' subset | valid_loss 4.32407 | valid_nll_loss 2.89912 | valid_ppl 7.46 | num_updates 7952 | best 4.32407\u001b[0m\n",
      "\u001b[31m| epoch 057 | loss 4.272 | nll_loss 2.842 | ppl 7.17 | wps 195304 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 8094 | lr 0.25 | gnorm 0.136 | clip 100% | oom 0 | wall 1194 | train_wall 1001\u001b[0m\n",
      "\u001b[31m| epoch 057 | valid on 'valid' subset | valid_loss 4.31888 | valid_nll_loss 2.89674 | valid_ppl 7.45 | num_updates 8094 | best 4.31888\u001b[0m\n",
      "\u001b[31m| epoch 058 | loss 4.265 | nll_loss 2.834 | ppl 7.13 | wps 193916 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 8236 | lr 0.25 | gnorm 0.135 | clip 100% | oom 0 | wall 1215 | train_wall 1019\u001b[0m\n",
      "\u001b[31m| epoch 058 | valid on 'valid' subset | valid_loss 4.31653 | valid_nll_loss 2.89078 | valid_ppl 7.42 | num_updates 8236 | best 4.31653\u001b[0m\n",
      "\u001b[31m| epoch 059 | loss 4.258 | nll_loss 2.826 | ppl 7.09 | wps 197344 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 8378 | lr 0.25 | gnorm 0.134 | clip 100% | oom 0 | wall 1236 | train_wall 1036\u001b[0m\n",
      "\u001b[31m| epoch 059 | valid on 'valid' subset | valid_loss 4.32803 | valid_nll_loss 2.89236 | valid_ppl 7.42 | num_updates 8378 | best 4.31653\u001b[0m\n",
      "\u001b[31m| epoch 060 | loss 4.251 | nll_loss 2.817 | ppl 7.05 | wps 195544 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 8520 | lr 0.25 | gnorm 0.135 | clip 100% | oom 0 | wall 1256 | train_wall 1054\u001b[0m\n",
      "\u001b[31m| epoch 060 | valid on 'valid' subset | valid_loss 4.31214 | valid_nll_loss 2.88044 | valid_ppl 7.36 | num_updates 8520 | best 4.31214\u001b[0m\n",
      "\u001b[31m| epoch 061 | loss 4.245 | nll_loss 2.811 | ppl 7.02 | wps 193268 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 8662 | lr 0.25 | gnorm 0.133 | clip 100% | oom 0 | wall 1278 | train_wall 1072\u001b[0m\n",
      "\u001b[31m| epoch 061 | valid on 'valid' subset | valid_loss 4.30836 | valid_nll_loss 2.87367 | valid_ppl 7.33 | num_updates 8662 | best 4.30836\u001b[0m\n",
      "\u001b[31m| epoch 062 | loss 4.239 | nll_loss 2.803 | ppl 6.98 | wps 197192 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 8804 | lr 0.25 | gnorm 0.134 | clip 100% | oom 0 | wall 1298 | train_wall 1089\u001b[0m\n",
      "\u001b[31m| epoch 062 | valid on 'valid' subset | valid_loss 4.30216 | valid_nll_loss 2.8715 | valid_ppl 7.32 | num_updates 8804 | best 4.30216\u001b[0m\n",
      "\u001b[31m| epoch 063 | loss 4.233 | nll_loss 2.796 | ppl 6.95 | wps 196278 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 8946 | lr 0.25 | gnorm 0.134 | clip 100% | oom 0 | wall 1319 | train_wall 1107\u001b[0m\n",
      "\u001b[31m| epoch 063 | valid on 'valid' subset | valid_loss 4.29832 | valid_nll_loss 2.87137 | valid_ppl 7.32 | num_updates 8946 | best 4.29832\u001b[0m\n",
      "\u001b[31m| epoch 064 | loss 4.227 | nll_loss 2.789 | ppl 6.91 | wps 193999 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 9088 | lr 0.25 | gnorm 0.133 | clip 100% | oom 0 | wall 1340 | train_wall 1124\u001b[0m\n",
      "\u001b[31m| epoch 064 | valid on 'valid' subset | valid_loss 4.30194 | valid_nll_loss 2.86905 | valid_ppl 7.31 | num_updates 9088 | best 4.29832\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 065 | loss 4.221 | nll_loss 2.783 | ppl 6.88 | wps 196311 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 9230 | lr 0.25 | gnorm 0.136 | clip 100% | oom 0 | wall 1361 | train_wall 1142\u001b[0m\n",
      "\u001b[31m| epoch 065 | valid on 'valid' subset | valid_loss 4.29163 | valid_nll_loss 2.866 | valid_ppl 7.29 | num_updates 9230 | best 4.29163\u001b[0m\n",
      "\u001b[31m| epoch 066 | loss 4.215 | nll_loss 2.776 | ppl 6.85 | wps 194740 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 9372 | lr 0.25 | gnorm 0.135 | clip 100% | oom 0 | wall 1382 | train_wall 1159\u001b[0m\n",
      "\u001b[31m| epoch 066 | valid on 'valid' subset | valid_loss 4.29269 | valid_nll_loss 2.86084 | valid_ppl 7.26 | num_updates 9372 | best 4.29163\u001b[0m\n",
      "\u001b[31m| epoch 067 | loss 4.208 | nll_loss 2.768 | ppl 6.81 | wps 194554 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 9514 | lr 0.25 | gnorm 0.133 | clip 100% | oom 0 | wall 1403 | train_wall 1177\u001b[0m\n",
      "\u001b[31m| epoch 067 | valid on 'valid' subset | valid_loss 4.28482 | valid_nll_loss 2.85499 | valid_ppl 7.23 | num_updates 9514 | best 4.28482\u001b[0m\n",
      "\u001b[31m| epoch 068 | loss 4.204 | nll_loss 2.763 | ppl 6.79 | wps 197570 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 9656 | lr 0.25 | gnorm 0.133 | clip 100% | oom 0 | wall 1424 | train_wall 1194\u001b[0m\n",
      "\u001b[31m| epoch 068 | valid on 'valid' subset | valid_loss 4.28456 | valid_nll_loss 2.85234 | valid_ppl 7.22 | num_updates 9656 | best 4.28456\u001b[0m\n",
      "\u001b[31m| epoch 069 | loss 4.199 | nll_loss 2.758 | ppl 6.76 | wps 194734 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 9798 | lr 0.25 | gnorm 0.132 | clip 100% | oom 0 | wall 1445 | train_wall 1212\u001b[0m\n",
      "\u001b[31m| epoch 069 | valid on 'valid' subset | valid_loss 4.28296 | valid_nll_loss 2.84649 | valid_ppl 7.19 | num_updates 9798 | best 4.28296\u001b[0m\n",
      "\u001b[31m| epoch 070 | loss 4.193 | nll_loss 2.751 | ppl 6.73 | wps 193252 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 9940 | lr 0.25 | gnorm 0.132 | clip 100% | oom 0 | wall 1466 | train_wall 1230\u001b[0m\n",
      "\u001b[31m| epoch 070 | valid on 'valid' subset | valid_loss 4.28163 | valid_nll_loss 2.84303 | valid_ppl 7.18 | num_updates 9940 | best 4.28163\u001b[0m\n",
      "\u001b[31m| epoch 071 | loss 4.188 | nll_loss 2.744 | ppl 6.70 | wps 197679 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 10082 | lr 0.25 | gnorm 0.132 | clip 100% | oom 0 | wall 1487 | train_wall 1247\u001b[0m\n",
      "\u001b[31m| epoch 071 | valid on 'valid' subset | valid_loss 4.27955 | valid_nll_loss 2.84553 | valid_ppl 7.19 | num_updates 10082 | best 4.27955\u001b[0m\n",
      "\u001b[31m| epoch 072 | loss 4.184 | nll_loss 2.740 | ppl 6.68 | wps 197129 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 10224 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1508 | train_wall 1264\u001b[0m\n",
      "\u001b[31m| epoch 072 | valid on 'valid' subset | valid_loss 4.27473 | valid_nll_loss 2.84068 | valid_ppl 7.16 | num_updates 10224 | best 4.27473\u001b[0m\n",
      "\u001b[31m| epoch 073 | loss 4.180 | nll_loss 2.735 | ppl 6.66 | wps 196473 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 10366 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1528 | train_wall 1282\u001b[0m\n",
      "\u001b[31m| epoch 073 | valid on 'valid' subset | valid_loss 4.26838 | valid_nll_loss 2.83538 | valid_ppl 7.14 | num_updates 10366 | best 4.26838\u001b[0m\n",
      "\u001b[31m| epoch 074 | loss 4.174 | nll_loss 2.728 | ppl 6.62 | wps 195264 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 10508 | lr 0.25 | gnorm 0.132 | clip 100% | oom 0 | wall 1549 | train_wall 1299\u001b[0m\n",
      "\u001b[31m| epoch 074 | valid on 'valid' subset | valid_loss 4.27996 | valid_nll_loss 2.84061 | valid_ppl 7.16 | num_updates 10508 | best 4.26838\u001b[0m\n",
      "\u001b[31m| epoch 075 | loss 4.169 | nll_loss 2.722 | ppl 6.60 | wps 194586 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 10650 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1570 | train_wall 1317\u001b[0m\n",
      "\u001b[31m| epoch 075 | valid on 'valid' subset | valid_loss 4.2696 | valid_nll_loss 2.82795 | valid_ppl 7.10 | num_updates 10650 | best 4.26838\u001b[0m\n",
      "\u001b[31m| epoch 076 | loss 4.163 | nll_loss 2.716 | ppl 6.57 | wps 197102 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 10792 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1591 | train_wall 1334\u001b[0m\n",
      "\u001b[31m| epoch 076 | valid on 'valid' subset | valid_loss 4.26297 | valid_nll_loss 2.82395 | valid_ppl 7.08 | num_updates 10792 | best 4.26297\u001b[0m\n",
      "\u001b[31m| epoch 077 | loss 4.161 | nll_loss 2.713 | ppl 6.56 | wps 195975 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 10934 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1612 | train_wall 1352\u001b[0m\n",
      "\u001b[31m| epoch 077 | valid on 'valid' subset | valid_loss 4.26711 | valid_nll_loss 2.824 | valid_ppl 7.08 | num_updates 10934 | best 4.26297\u001b[0m\n",
      "\u001b[31m| epoch 078 | loss 4.156 | nll_loss 2.708 | ppl 6.53 | wps 192935 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 11076 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1633 | train_wall 1369\u001b[0m\n",
      "\u001b[31m| epoch 078 | valid on 'valid' subset | valid_loss 4.25785 | valid_nll_loss 2.81888 | valid_ppl 7.06 | num_updates 11076 | best 4.25785\u001b[0m\n",
      "\u001b[31m| epoch 079 | loss 4.152 | nll_loss 2.703 | ppl 6.51 | wps 197082 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 11218 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1654 | train_wall 1387\u001b[0m\n",
      "\u001b[31m| epoch 079 | valid on 'valid' subset | valid_loss 4.25996 | valid_nll_loss 2.81737 | valid_ppl 7.05 | num_updates 11218 | best 4.25785\u001b[0m\n",
      "\u001b[31m| epoch 080 | loss 4.147 | nll_loss 2.697 | ppl 6.48 | wps 193313 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 11360 | lr 0.25 | gnorm 0.131 | clip 100% | oom 0 | wall 1675 | train_wall 1405\u001b[0m\n",
      "\u001b[31m| epoch 080 | valid on 'valid' subset | valid_loss 4.25658 | valid_nll_loss 2.81721 | valid_ppl 7.05 | num_updates 11360 | best 4.25658\u001b[0m\n",
      "\u001b[31m| epoch 081 | loss 4.142 | nll_loss 2.692 | ppl 6.46 | wps 195129 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 11502 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1696 | train_wall 1422\u001b[0m\n",
      "\u001b[31m| epoch 081 | valid on 'valid' subset | valid_loss 4.26213 | valid_nll_loss 2.81071 | valid_ppl 7.02 | num_updates 11502 | best 4.25658\u001b[0m\n",
      "\u001b[31m| epoch 082 | loss 4.139 | nll_loss 2.688 | ppl 6.44 | wps 195905 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 11644 | lr 0.25 | gnorm 0.130 | clip 100% | oom 0 | wall 1717 | train_wall 1440\u001b[0m\n",
      "\u001b[31m| epoch 082 | valid on 'valid' subset | valid_loss 4.2553 | valid_nll_loss 2.8129 | valid_ppl 7.03 | num_updates 11644 | best 4.2553\u001b[0m\n",
      "\u001b[31m| epoch 083 | loss 4.135 | nll_loss 2.683 | ppl 6.42 | wps 192658 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 11786 | lr 0.25 | gnorm 0.130 | clip 100% | oom 0 | wall 1738 | train_wall 1458\u001b[0m\n",
      "\u001b[31m| epoch 083 | valid on 'valid' subset | valid_loss 4.24898 | valid_nll_loss 2.80712 | valid_ppl 7.00 | num_updates 11786 | best 4.24898\u001b[0m\n",
      "\u001b[31m| epoch 084 | loss 4.130 | nll_loss 2.677 | ppl 6.40 | wps 194840 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 11928 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1759 | train_wall 1476\u001b[0m\n",
      "\u001b[31m| epoch 084 | valid on 'valid' subset | valid_loss 4.24906 | valid_nll_loss 2.80455 | valid_ppl 6.99 | num_updates 11928 | best 4.24898\u001b[0m\n",
      "\u001b[31m| epoch 085 | loss 4.127 | nll_loss 2.673 | ppl 6.38 | wps 195829 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 12070 | lr 0.25 | gnorm 0.128 | clip 99% | oom 0 | wall 1780 | train_wall 1493\u001b[0m\n",
      "\u001b[31m| epoch 085 | valid on 'valid' subset | valid_loss 4.25565 | valid_nll_loss 2.81018 | valid_ppl 7.01 | num_updates 12070 | best 4.24898\u001b[0m\n",
      "\u001b[31m| epoch 086 | loss 4.122 | nll_loss 2.668 | ppl 6.36 | wps 194595 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 12212 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1801 | train_wall 1511\u001b[0m\n",
      "\u001b[31m| epoch 086 | valid on 'valid' subset | valid_loss 4.24649 | valid_nll_loss 2.79911 | valid_ppl 6.96 | num_updates 12212 | best 4.24649\u001b[0m\n",
      "\u001b[31m| epoch 087 | loss 4.119 | nll_loss 2.664 | ppl 6.34 | wps 192718 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 12354 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1822 | train_wall 1529\u001b[0m\n",
      "\u001b[31m| epoch 087 | valid on 'valid' subset | valid_loss 4.24679 | valid_nll_loss 2.79932 | valid_ppl 6.96 | num_updates 12354 | best 4.24649\u001b[0m\n",
      "\u001b[31m| epoch 088 | loss 4.116 | nll_loss 2.660 | ppl 6.32 | wps 194706 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 12496 | lr 0.25 | gnorm 0.130 | clip 100% | oom 0 | wall 1843 | train_wall 1546\u001b[0m\n",
      "\u001b[31m| epoch 088 | valid on 'valid' subset | valid_loss 4.24185 | valid_nll_loss 2.79727 | valid_ppl 6.95 | num_updates 12496 | best 4.24185\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 089 | loss 4.112 | nll_loss 2.656 | ppl 6.30 | wps 195801 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 12638 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1864 | train_wall 1564\u001b[0m\n",
      "\u001b[31m| epoch 089 | valid on 'valid' subset | valid_loss 4.24336 | valid_nll_loss 2.79807 | valid_ppl 6.96 | num_updates 12638 | best 4.24185\u001b[0m\n",
      "\u001b[31m| epoch 090 | loss 4.109 | nll_loss 2.652 | ppl 6.29 | wps 194820 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 12780 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1885 | train_wall 1582\u001b[0m\n",
      "\u001b[31m| epoch 090 | valid on 'valid' subset | valid_loss 4.24087 | valid_nll_loss 2.79213 | valid_ppl 6.93 | num_updates 12780 | best 4.24087\u001b[0m\n",
      "\u001b[31m| epoch 091 | loss 4.104 | nll_loss 2.647 | ppl 6.27 | wps 198287 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 12922 | lr 0.25 | gnorm 0.126 | clip 99% | oom 0 | wall 1906 | train_wall 1599\u001b[0m\n",
      "\u001b[31m| epoch 091 | valid on 'valid' subset | valid_loss 4.23347 | valid_nll_loss 2.79233 | valid_ppl 6.93 | num_updates 12922 | best 4.23347\u001b[0m\n",
      "\u001b[31m| epoch 092 | loss 4.100 | nll_loss 2.643 | ppl 6.25 | wps 196508 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13064 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 1926 | train_wall 1616\u001b[0m\n",
      "\u001b[31m| epoch 092 | valid on 'valid' subset | valid_loss 4.23941 | valid_nll_loss 2.793 | valid_ppl 6.93 | num_updates 13064 | best 4.23347\u001b[0m\n",
      "\u001b[31m| epoch 093 | loss 4.097 | nll_loss 2.639 | ppl 6.23 | wps 195940 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13206 | lr 0.25 | gnorm 0.127 | clip 100% | oom 0 | wall 1947 | train_wall 1634\u001b[0m\n",
      "\u001b[31m| epoch 093 | valid on 'valid' subset | valid_loss 4.22998 | valid_nll_loss 2.78522 | valid_ppl 6.89 | num_updates 13206 | best 4.22998\u001b[0m\n",
      "\u001b[31m| epoch 094 | loss 4.095 | nll_loss 2.636 | ppl 6.22 | wps 195088 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13348 | lr 0.25 | gnorm 0.128 | clip 99% | oom 0 | wall 1968 | train_wall 1652\u001b[0m\n",
      "\u001b[31m| epoch 094 | valid on 'valid' subset | valid_loss 4.23844 | valid_nll_loss 2.78718 | valid_ppl 6.90 | num_updates 13348 | best 4.22998\u001b[0m\n",
      "\u001b[31m| epoch 095 | loss 4.091 | nll_loss 2.631 | ppl 6.20 | wps 197209 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13490 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 1989 | train_wall 1669\u001b[0m\n",
      "\u001b[31m| epoch 095 | valid on 'valid' subset | valid_loss 4.23432 | valid_nll_loss 2.78384 | valid_ppl 6.89 | num_updates 13490 | best 4.22998\u001b[0m\n",
      "\u001b[31m| epoch 096 | loss 4.089 | nll_loss 2.629 | ppl 6.19 | wps 195241 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13632 | lr 0.25 | gnorm 0.127 | clip 100% | oom 0 | wall 2010 | train_wall 1687\u001b[0m\n",
      "\u001b[31m| epoch 096 | valid on 'valid' subset | valid_loss 4.22698 | valid_nll_loss 2.78662 | valid_ppl 6.90 | num_updates 13632 | best 4.22698\u001b[0m\n",
      "\u001b[31m| epoch 097 | loss 4.084 | nll_loss 2.624 | ppl 6.16 | wps 195887 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13774 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 2031 | train_wall 1704\u001b[0m\n",
      "\u001b[31m| epoch 097 | valid on 'valid' subset | valid_loss 4.22435 | valid_nll_loss 2.78002 | valid_ppl 6.87 | num_updates 13774 | best 4.22435\u001b[0m\n",
      "\u001b[31m| epoch 098 | loss 4.082 | nll_loss 2.621 | ppl 6.15 | wps 196206 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 13916 | lr 0.25 | gnorm 0.127 | clip 100% | oom 0 | wall 2052 | train_wall 1722\u001b[0m\n",
      "\u001b[31m| epoch 098 | valid on 'valid' subset | valid_loss 4.22437 | valid_nll_loss 2.77753 | valid_ppl 6.86 | num_updates 13916 | best 4.22435\u001b[0m\n",
      "\u001b[31m| epoch 099 | loss 4.078 | nll_loss 2.617 | ppl 6.13 | wps 197126 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 14058 | lr 0.25 | gnorm 0.127 | clip 100% | oom 0 | wall 2072 | train_wall 1739\u001b[0m\n",
      "\u001b[31m| epoch 099 | valid on 'valid' subset | valid_loss 4.22286 | valid_nll_loss 2.77412 | valid_ppl 6.84 | num_updates 14058 | best 4.22286\u001b[0m\n",
      "\u001b[31m| epoch 100 | loss 4.074 | nll_loss 2.612 | ppl 6.11 | wps 195634 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 14200 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 2093 | train_wall 1757\u001b[0m\n",
      "\u001b[31m| epoch 100 | valid on 'valid' subset | valid_loss 4.22394 | valid_nll_loss 2.76906 | valid_ppl 6.82 | num_updates 14200 | best 4.22286\u001b[0m\n",
      "\u001b[31m| epoch 101 | loss 4.072 | nll_loss 2.610 | ppl 6.11 | wps 193941 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 14342 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 2114 | train_wall 1774\u001b[0m\n",
      "\u001b[31m| epoch 101 | valid on 'valid' subset | valid_loss 4.22063 | valid_nll_loss 2.77384 | valid_ppl 6.84 | num_updates 14342 | best 4.22063\u001b[0m\n",
      "\u001b[31m| epoch 102 | loss 4.069 | nll_loss 2.606 | ppl 6.09 | wps 194708 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 14484 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 2135 | train_wall 1792\u001b[0m\n",
      "\u001b[31m| epoch 102 | valid on 'valid' subset | valid_loss 4.22683 | valid_nll_loss 2.77767 | valid_ppl 6.86 | num_updates 14484 | best 4.22063\u001b[0m\n",
      "\u001b[31m| epoch 103 | loss 4.066 | nll_loss 2.603 | ppl 6.07 | wps 194088 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 14626 | lr 0.25 | gnorm 0.128 | clip 100% | oom 0 | wall 2156 | train_wall 1810\u001b[0m\n",
      "\u001b[31m| epoch 103 | valid on 'valid' subset | valid_loss 4.22001 | valid_nll_loss 2.76952 | valid_ppl 6.82 | num_updates 14626 | best 4.22001\u001b[0m\n",
      "\u001b[31m| epoch 104 | loss 4.063 | nll_loss 2.599 | ppl 6.06 | wps 195980 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 14768 | lr 0.25 | gnorm 0.125 | clip 100% | oom 0 | wall 2177 | train_wall 1828\u001b[0m\n",
      "\u001b[31m| epoch 104 | valid on 'valid' subset | valid_loss 4.22444 | valid_nll_loss 2.77074 | valid_ppl 6.82 | num_updates 14768 | best 4.22001\u001b[0m\n",
      "\u001b[31m| epoch 105 | loss 4.060 | nll_loss 2.596 | ppl 6.05 | wps 196361 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 14910 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 2198 | train_wall 1845\u001b[0m\n",
      "\u001b[31m| epoch 105 | valid on 'valid' subset | valid_loss 4.22515 | valid_nll_loss 2.76683 | valid_ppl 6.81 | num_updates 14910 | best 4.22001\u001b[0m\n",
      "\u001b[31m| epoch 106 | loss 4.058 | nll_loss 2.594 | ppl 6.04 | wps 195756 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 15052 | lr 0.25 | gnorm 0.126 | clip 100% | oom 0 | wall 2219 | train_wall 1863\u001b[0m\n",
      "\u001b[31m| epoch 106 | valid on 'valid' subset | valid_loss 4.22044 | valid_nll_loss 2.76239 | valid_ppl 6.79 | num_updates 15052 | best 4.22001\u001b[0m\n",
      "\u001b[31m| epoch 107 | loss 4.056 | nll_loss 2.591 | ppl 6.03 | wps 194932 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 15194 | lr 0.25 | gnorm 0.125 | clip 100% | oom 0 | wall 2240 | train_wall 1880\u001b[0m\n",
      "\u001b[31m| epoch 107 | valid on 'valid' subset | valid_loss 4.22358 | valid_nll_loss 2.76387 | valid_ppl 6.79 | num_updates 15194 | best 4.22001\u001b[0m\n",
      "\u001b[31m| epoch 108 | loss 4.053 | nll_loss 2.587 | ppl 6.01 | wps 193417 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 15336 | lr 0.25 | gnorm 0.124 | clip 100% | oom 0 | wall 2261 | train_wall 1898\u001b[0m\n",
      "\u001b[31m| epoch 108 | valid on 'valid' subset | valid_loss 4.22289 | valid_nll_loss 2.76777 | valid_ppl 6.81 | num_updates 15336 | best 4.22001\u001b[0m\n",
      "\u001b[31m| epoch 109 | loss 4.050 | nll_loss 2.584 | ppl 6.00 | wps 195067 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 15478 | lr 0.25 | gnorm 0.126 | clip 99% | oom 0 | wall 2282 | train_wall 1916\u001b[0m\n",
      "\u001b[31m| epoch 109 | valid on 'valid' subset | valid_loss 4.21392 | valid_nll_loss 2.76257 | valid_ppl 6.79 | num_updates 15478 | best 4.21392\u001b[0m\n",
      "\u001b[31m| epoch 110 | loss 4.046 | nll_loss 2.579 | ppl 5.98 | wps 196774 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 15620 | lr 0.25 | gnorm 0.122 | clip 99% | oom 0 | wall 2302 | train_wall 1934\u001b[0m\n",
      "\u001b[31m| epoch 110 | valid on 'valid' subset | valid_loss 4.20775 | valid_nll_loss 2.75979 | valid_ppl 6.77 | num_updates 15620 | best 4.20775\u001b[0m\n",
      "\u001b[31m| epoch 111 | loss 4.044 | nll_loss 2.577 | ppl 5.97 | wps 196980 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 15762 | lr 0.25 | gnorm 0.125 | clip 99% | oom 0 | wall 2323 | train_wall 1951\u001b[0m\n",
      "\u001b[31m| epoch 111 | valid on 'valid' subset | valid_loss 4.21471 | valid_nll_loss 2.76799 | valid_ppl 6.81 | num_updates 15762 | best 4.20775\u001b[0m\n",
      "\u001b[31m| epoch 112 | loss 4.041 | nll_loss 2.574 | ppl 5.95 | wps 197122 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 15904 | lr 0.25 | gnorm 0.123 | clip 100% | oom 0 | wall 2344 | train_wall 1969\u001b[0m\n",
      "\u001b[31m| epoch 112 | valid on 'valid' subset | valid_loss 4.20533 | valid_nll_loss 2.76062 | valid_ppl 6.78 | num_updates 15904 | best 4.20533\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 113 | loss 4.038 | nll_loss 2.570 | ppl 5.94 | wps 194889 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16046 | lr 0.25 | gnorm 0.123 | clip 100% | oom 0 | wall 2365 | train_wall 1986\u001b[0m\n",
      "\u001b[31m| epoch 113 | valid on 'valid' subset | valid_loss 4.21808 | valid_nll_loss 2.76184 | valid_ppl 6.78 | num_updates 16046 | best 4.20533\u001b[0m\n",
      "\u001b[31m| epoch 114 | loss 4.036 | nll_loss 2.568 | ppl 5.93 | wps 193966 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16188 | lr 0.25 | gnorm 0.125 | clip 100% | oom 0 | wall 2386 | train_wall 2004\u001b[0m\n",
      "\u001b[31m| epoch 114 | valid on 'valid' subset | valid_loss 4.2023 | valid_nll_loss 2.75497 | valid_ppl 6.75 | num_updates 16188 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 115 | loss 4.033 | nll_loss 2.564 | ppl 5.92 | wps 196668 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16330 | lr 0.25 | gnorm 0.126 | clip 99% | oom 0 | wall 2407 | train_wall 2021\u001b[0m\n",
      "\u001b[31m| epoch 115 | valid on 'valid' subset | valid_loss 4.20354 | valid_nll_loss 2.7505 | valid_ppl 6.73 | num_updates 16330 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 116 | loss 4.030 | nll_loss 2.561 | ppl 5.90 | wps 196493 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16472 | lr 0.25 | gnorm 0.123 | clip 100% | oom 0 | wall 2428 | train_wall 2039\u001b[0m\n",
      "\u001b[31m| epoch 116 | valid on 'valid' subset | valid_loss 4.20758 | valid_nll_loss 2.75079 | valid_ppl 6.73 | num_updates 16472 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 117 | loss 4.028 | nll_loss 2.559 | ppl 5.89 | wps 194760 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16614 | lr 0.25 | gnorm 0.124 | clip 99% | oom 0 | wall 2449 | train_wall 2056\u001b[0m\n",
      "\u001b[31m| epoch 117 | valid on 'valid' subset | valid_loss 4.20848 | valid_nll_loss 2.7513 | valid_ppl 6.73 | num_updates 16614 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 118 | loss 4.026 | nll_loss 2.556 | ppl 5.88 | wps 195061 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16756 | lr 0.25 | gnorm 0.125 | clip 99% | oom 0 | wall 2469 | train_wall 2074\u001b[0m\n",
      "\u001b[31m| epoch 118 | valid on 'valid' subset | valid_loss 4.20752 | valid_nll_loss 2.75402 | valid_ppl 6.75 | num_updates 16756 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 119 | loss 4.024 | nll_loss 2.553 | ppl 5.87 | wps 194468 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 16898 | lr 0.25 | gnorm 0.123 | clip 99% | oom 0 | wall 2490 | train_wall 2091\u001b[0m\n",
      "\u001b[31m| epoch 119 | valid on 'valid' subset | valid_loss 4.20252 | valid_nll_loss 2.74716 | valid_ppl 6.71 | num_updates 16898 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 120 | loss 4.023 | nll_loss 2.552 | ppl 5.87 | wps 195520 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17040 | lr 0.25 | gnorm 0.122 | clip 99% | oom 0 | wall 2511 | train_wall 2109\u001b[0m\n",
      "\u001b[31m| epoch 120 | valid on 'valid' subset | valid_loss 4.20993 | valid_nll_loss 2.7538 | valid_ppl 6.74 | num_updates 17040 | best 4.2023\u001b[0m\n",
      "\u001b[31m| epoch 121 | loss 4.020 | nll_loss 2.548 | ppl 5.85 | wps 195520 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17182 | lr 0.25 | gnorm 0.125 | clip 100% | oom 0 | wall 2532 | train_wall 2127\u001b[0m\n",
      "\u001b[31m| epoch 121 | valid on 'valid' subset | valid_loss 4.20057 | valid_nll_loss 2.7551 | valid_ppl 6.75 | num_updates 17182 | best 4.20057\u001b[0m\n",
      "\u001b[31m| epoch 122 | loss 4.017 | nll_loss 2.546 | ppl 5.84 | wps 194703 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17324 | lr 0.25 | gnorm 0.125 | clip 100% | oom 0 | wall 2553 | train_wall 2144\u001b[0m\n",
      "\u001b[31m| epoch 122 | valid on 'valid' subset | valid_loss 4.20713 | valid_nll_loss 2.74215 | valid_ppl 6.69 | num_updates 17324 | best 4.20057\u001b[0m\n",
      "\u001b[31m| epoch 123 | loss 4.014 | nll_loss 2.542 | ppl 5.83 | wps 194590 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17466 | lr 0.25 | gnorm 0.122 | clip 100% | oom 0 | wall 2574 | train_wall 2162\u001b[0m\n",
      "\u001b[31m| epoch 123 | valid on 'valid' subset | valid_loss 4.19797 | valid_nll_loss 2.74402 | valid_ppl 6.70 | num_updates 17466 | best 4.19797\u001b[0m\n",
      "\u001b[31m| epoch 124 | loss 4.012 | nll_loss 2.540 | ppl 5.82 | wps 196049 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17608 | lr 0.25 | gnorm 0.123 | clip 100% | oom 0 | wall 2595 | train_wall 2180\u001b[0m\n",
      "\u001b[31m| epoch 124 | valid on 'valid' subset | valid_loss 4.19403 | valid_nll_loss 2.73983 | valid_ppl 6.68 | num_updates 17608 | best 4.19403\u001b[0m\n",
      "\u001b[31m| epoch 125 | loss 4.010 | nll_loss 2.538 | ppl 5.81 | wps 195395 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17750 | lr 0.25 | gnorm 0.125 | clip 100% | oom 0 | wall 2616 | train_wall 2197\u001b[0m\n",
      "\u001b[31m| epoch 125 | valid on 'valid' subset | valid_loss 4.20423 | valid_nll_loss 2.74682 | valid_ppl 6.71 | num_updates 17750 | best 4.19403\u001b[0m\n",
      "\u001b[31m| epoch 126 | loss 4.007 | nll_loss 2.534 | ppl 5.79 | wps 195368 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 17892 | lr 0.25 | gnorm 0.122 | clip 100% | oom 0 | wall 2637 | train_wall 2215\u001b[0m\n",
      "\u001b[31m| epoch 126 | valid on 'valid' subset | valid_loss 4.19632 | valid_nll_loss 2.7407 | valid_ppl 6.68 | num_updates 17892 | best 4.19403\u001b[0m\n",
      "\u001b[31m| epoch 127 | loss 4.006 | nll_loss 2.533 | ppl 5.79 | wps 196235 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 18034 | lr 0.25 | gnorm 0.123 | clip 99% | oom 0 | wall 2658 | train_wall 2232\u001b[0m\n",
      "\u001b[31m| epoch 127 | valid on 'valid' subset | valid_loss 4.20563 | valid_nll_loss 2.74488 | valid_ppl 6.70 | num_updates 18034 | best 4.19403\u001b[0m\n",
      "\u001b[31m| epoch 128 | loss 4.005 | nll_loss 2.532 | ppl 5.78 | wps 195041 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 18176 | lr 0.25 | gnorm 0.124 | clip 100% | oom 0 | wall 2678 | train_wall 2250\u001b[0m\n",
      "\u001b[31m| epoch 128 | valid on 'valid' subset | valid_loss 4.20295 | valid_nll_loss 2.74465 | valid_ppl 6.70 | num_updates 18176 | best 4.19403\u001b[0m\n",
      "\u001b[31m| epoch 129 | loss 4.000 | nll_loss 2.527 | ppl 5.76 | wps 195775 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 18318 | lr 0.25 | gnorm 0.122 | clip 99% | oom 0 | wall 2699 | train_wall 2268\u001b[0m\n",
      "\u001b[31m| epoch 129 | valid on 'valid' subset | valid_loss 4.18815 | valid_nll_loss 2.73619 | valid_ppl 6.66 | num_updates 18318 | best 4.18815\u001b[0m\n",
      "\u001b[31m| epoch 130 | loss 3.997 | nll_loss 2.523 | ppl 5.75 | wps 193083 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 18460 | lr 0.25 | gnorm 0.121 | clip 100% | oom 0 | wall 2721 | train_wall 2285\u001b[0m\n",
      "\u001b[31m| epoch 130 | valid on 'valid' subset | valid_loss 4.19117 | valid_nll_loss 2.73364 | valid_ppl 6.65 | num_updates 18460 | best 4.18815\u001b[0m\n",
      "\u001b[31m| epoch 131 | loss 3.996 | nll_loss 2.521 | ppl 5.74 | wps 195301 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 18602 | lr 0.25 | gnorm 0.121 | clip 97% | oom 0 | wall 2741 | train_wall 2303\u001b[0m\n",
      "\u001b[31m| epoch 131 | valid on 'valid' subset | valid_loss 4.19584 | valid_nll_loss 2.73994 | valid_ppl 6.68 | num_updates 18602 | best 4.18815\u001b[0m\n",
      "\u001b[31m| epoch 132 | loss 3.995 | nll_loss 2.520 | ppl 5.73 | wps 195492 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 18744 | lr 0.25 | gnorm 0.123 | clip 100% | oom 0 | wall 2762 | train_wall 2321\u001b[0m\n",
      "\u001b[31m| epoch 132 | valid on 'valid' subset | valid_loss 4.19679 | valid_nll_loss 2.73501 | valid_ppl 6.66 | num_updates 18744 | best 4.18815\u001b[0m\n",
      "\u001b[31m| epoch 133 | loss 3.993 | nll_loss 2.518 | ppl 5.73 | wps 195504 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 18886 | lr 0.25 | gnorm 0.122 | clip 99% | oom 0 | wall 2783 | train_wall 2338\u001b[0m\n",
      "\u001b[31m| epoch 133 | valid on 'valid' subset | valid_loss 4.2009 | valid_nll_loss 2.74138 | valid_ppl 6.69 | num_updates 18886 | best 4.18815\u001b[0m\n",
      "\u001b[31m| epoch 134 | loss 3.992 | nll_loss 2.516 | ppl 5.72 | wps 197682 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 19028 | lr 0.25 | gnorm 0.121 | clip 99% | oom 0 | wall 2804 | train_wall 2355\u001b[0m\n",
      "\u001b[31m| epoch 134 | valid on 'valid' subset | valid_loss 4.18778 | valid_nll_loss 2.73075 | valid_ppl 6.64 | num_updates 19028 | best 4.18778\u001b[0m\n",
      "\u001b[31m| epoch 135 | loss 3.990 | nll_loss 2.514 | ppl 5.71 | wps 196240 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 19170 | lr 0.25 | gnorm 0.122 | clip 99% | oom 0 | wall 2825 | train_wall 2373\u001b[0m\n",
      "\u001b[31m| epoch 135 | valid on 'valid' subset | valid_loss 4.19293 | valid_nll_loss 2.73359 | valid_ppl 6.65 | num_updates 19170 | best 4.18778\u001b[0m\n",
      "\u001b[31m| epoch 136 | loss 3.986 | nll_loss 2.510 | ppl 5.70 | wps 195978 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 19312 | lr 0.25 | gnorm 0.121 | clip 100% | oom 0 | wall 2846 | train_wall 2390\u001b[0m\n",
      "\u001b[31m| epoch 136 | valid on 'valid' subset | valid_loss 4.18275 | valid_nll_loss 2.73356 | valid_ppl 6.65 | num_updates 19312 | best 4.18275\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 137 | loss 3.985 | nll_loss 2.508 | ppl 5.69 | wps 194455 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 19454 | lr 0.25 | gnorm 0.120 | clip 99% | oom 0 | wall 2867 | train_wall 2408\u001b[0m\n",
      "\u001b[31m| epoch 137 | valid on 'valid' subset | valid_loss 4.1852 | valid_nll_loss 2.72947 | valid_ppl 6.63 | num_updates 19454 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 138 | loss 3.982 | nll_loss 2.506 | ppl 5.68 | wps 197923 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 19596 | lr 0.25 | gnorm 0.120 | clip 99% | oom 0 | wall 2887 | train_wall 2425\u001b[0m\n",
      "\u001b[31m| epoch 138 | valid on 'valid' subset | valid_loss 4.18651 | valid_nll_loss 2.72689 | valid_ppl 6.62 | num_updates 19596 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 139 | loss 3.980 | nll_loss 2.503 | ppl 5.67 | wps 196977 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 19738 | lr 0.25 | gnorm 0.120 | clip 100% | oom 0 | wall 2908 | train_wall 2443\u001b[0m\n",
      "\u001b[31m| epoch 139 | valid on 'valid' subset | valid_loss 4.19032 | valid_nll_loss 2.72522 | valid_ppl 6.61 | num_updates 19738 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 140 | loss 3.979 | nll_loss 2.501 | ppl 5.66 | wps 194771 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 19880 | lr 0.25 | gnorm 0.119 | clip 99% | oom 0 | wall 2929 | train_wall 2460\u001b[0m\n",
      "\u001b[31m| epoch 140 | valid on 'valid' subset | valid_loss 4.19271 | valid_nll_loss 2.72669 | valid_ppl 6.62 | num_updates 19880 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 141 | loss 3.977 | nll_loss 2.499 | ppl 5.65 | wps 197030 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 20022 | lr 0.25 | gnorm 0.121 | clip 99% | oom 0 | wall 2950 | train_wall 2478\u001b[0m\n",
      "\u001b[31m| epoch 141 | valid on 'valid' subset | valid_loss 4.19086 | valid_nll_loss 2.72556 | valid_ppl 6.61 | num_updates 20022 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 142 | loss 3.975 | nll_loss 2.497 | ppl 5.65 | wps 193526 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 20164 | lr 0.25 | gnorm 0.121 | clip 98% | oom 0 | wall 2971 | train_wall 2496\u001b[0m\n",
      "\u001b[31m| epoch 142 | valid on 'valid' subset | valid_loss 4.19686 | valid_nll_loss 2.7274 | valid_ppl 6.62 | num_updates 20164 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 143 | loss 3.975 | nll_loss 2.496 | ppl 5.64 | wps 195478 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 20306 | lr 0.25 | gnorm 0.121 | clip 100% | oom 0 | wall 2992 | train_wall 2513\u001b[0m\n",
      "\u001b[31m| epoch 143 | valid on 'valid' subset | valid_loss 4.18339 | valid_nll_loss 2.72658 | valid_ppl 6.62 | num_updates 20306 | best 4.18275\u001b[0m\n",
      "\u001b[31m| epoch 144 | loss 3.971 | nll_loss 2.492 | ppl 5.63 | wps 194806 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 20448 | lr 0.25 | gnorm 0.120 | clip 99% | oom 0 | wall 3013 | train_wall 2530\u001b[0m\n",
      "\u001b[31m| epoch 144 | valid on 'valid' subset | valid_loss 4.18127 | valid_nll_loss 2.72424 | valid_ppl 6.61 | num_updates 20448 | best 4.18127\u001b[0m\n",
      "\u001b[31m| epoch 145 | loss 3.971 | nll_loss 2.492 | ppl 5.63 | wps 196794 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 20590 | lr 0.25 | gnorm 0.120 | clip 100% | oom 0 | wall 3033 | train_wall 2548\u001b[0m\n",
      "\u001b[31m| epoch 145 | valid on 'valid' subset | valid_loss 4.18012 | valid_nll_loss 2.72224 | valid_ppl 6.60 | num_updates 20590 | best 4.18012\u001b[0m\n",
      "\u001b[31m| epoch 146 | loss 3.968 | nll_loss 2.489 | ppl 5.61 | wps 194738 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 20732 | lr 0.25 | gnorm 0.120 | clip 100% | oom 0 | wall 3055 | train_wall 2565\u001b[0m\n",
      "\u001b[31m| epoch 146 | valid on 'valid' subset | valid_loss 4.18779 | valid_nll_loss 2.72576 | valid_ppl 6.62 | num_updates 20732 | best 4.18012\u001b[0m\n",
      "\u001b[31m| epoch 147 | loss 3.966 | nll_loss 2.487 | ppl 5.61 | wps 197226 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 20874 | lr 0.25 | gnorm 0.118 | clip 99% | oom 0 | wall 3075 | train_wall 2583\u001b[0m\n",
      "\u001b[31m| epoch 147 | valid on 'valid' subset | valid_loss 4.18576 | valid_nll_loss 2.72186 | valid_ppl 6.60 | num_updates 20874 | best 4.18012\u001b[0m\n",
      "\u001b[31m| epoch 148 | loss 3.965 | nll_loss 2.485 | ppl 5.60 | wps 198348 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 21016 | lr 0.25 | gnorm 0.119 | clip 96% | oom 0 | wall 3096 | train_wall 2600\u001b[0m\n",
      "\u001b[31m| epoch 148 | valid on 'valid' subset | valid_loss 4.19 | valid_nll_loss 2.72473 | valid_ppl 6.61 | num_updates 21016 | best 4.18012\u001b[0m\n",
      "\u001b[31m| epoch 149 | loss 3.962 | nll_loss 2.482 | ppl 5.59 | wps 195176 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 21158 | lr 0.25 | gnorm 0.118 | clip 99% | oom 0 | wall 3117 | train_wall 2618\u001b[0m\n",
      "\u001b[31m| epoch 149 | valid on 'valid' subset | valid_loss 4.18043 | valid_nll_loss 2.72314 | valid_ppl 6.60 | num_updates 21158 | best 4.18012\u001b[0m\n",
      "\u001b[31m| epoch 150 | loss 3.961 | nll_loss 2.480 | ppl 5.58 | wps 198102 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 21300 | lr 0.25 | gnorm 0.120 | clip 98% | oom 0 | wall 3137 | train_wall 2635\u001b[0m\n",
      "\u001b[31m| epoch 150 | valid on 'valid' subset | valid_loss 4.18444 | valid_nll_loss 2.7208 | valid_ppl 6.59 | num_updates 21300 | best 4.18012\u001b[0m\n",
      "\u001b[31m| epoch 151 | loss 3.959 | nll_loss 2.479 | ppl 5.58 | wps 195876 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 21442 | lr 0.25 | gnorm 0.117 | clip 97% | oom 0 | wall 3158 | train_wall 2653\u001b[0m\n",
      "\u001b[31m| epoch 151 | valid on 'valid' subset | valid_loss 4.17823 | valid_nll_loss 2.72047 | valid_ppl 6.59 | num_updates 21442 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 152 | loss 3.959 | nll_loss 2.478 | ppl 5.57 | wps 197216 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 21584 | lr 0.25 | gnorm 0.121 | clip 99% | oom 0 | wall 3179 | train_wall 2670\u001b[0m\n",
      "\u001b[31m| epoch 152 | valid on 'valid' subset | valid_loss 4.1857 | valid_nll_loss 2.71687 | valid_ppl 6.57 | num_updates 21584 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 153 | loss 3.955 | nll_loss 2.474 | ppl 5.55 | wps 194418 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 21726 | lr 0.25 | gnorm 0.118 | clip 97% | oom 0 | wall 3200 | train_wall 2688\u001b[0m\n",
      "\u001b[31m| epoch 153 | valid on 'valid' subset | valid_loss 4.19079 | valid_nll_loss 2.72366 | valid_ppl 6.61 | num_updates 21726 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 154 | loss 3.954 | nll_loss 2.473 | ppl 5.55 | wps 195992 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 21868 | lr 0.25 | gnorm 0.119 | clip 99% | oom 0 | wall 3221 | train_wall 2705\u001b[0m\n",
      "\u001b[31m| epoch 154 | valid on 'valid' subset | valid_loss 4.183 | valid_nll_loss 2.71703 | valid_ppl 6.58 | num_updates 21868 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 155 | loss 3.952 | nll_loss 2.470 | ppl 5.54 | wps 196730 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 22010 | lr 0.25 | gnorm 0.120 | clip 99% | oom 0 | wall 3241 | train_wall 2723\u001b[0m\n",
      "\u001b[31m| epoch 155 | valid on 'valid' subset | valid_loss 4.18124 | valid_nll_loss 2.72161 | valid_ppl 6.60 | num_updates 22010 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 156 | loss 3.950 | nll_loss 2.468 | ppl 5.53 | wps 196182 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 22152 | lr 0.25 | gnorm 0.118 | clip 99% | oom 0 | wall 3262 | train_wall 2740\u001b[0m\n",
      "\u001b[31m| epoch 156 | valid on 'valid' subset | valid_loss 4.17848 | valid_nll_loss 2.71603 | valid_ppl 6.57 | num_updates 22152 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 157 | loss 3.949 | nll_loss 2.466 | ppl 5.53 | wps 195029 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 22294 | lr 0.25 | gnorm 0.118 | clip 97% | oom 0 | wall 3283 | train_wall 2758\u001b[0m\n",
      "\u001b[31m| epoch 157 | valid on 'valid' subset | valid_loss 4.18 | valid_nll_loss 2.71729 | valid_ppl 6.58 | num_updates 22294 | best 4.17823\u001b[0m\n",
      "\u001b[31m| epoch 158 | loss 3.948 | nll_loss 2.466 | ppl 5.52 | wps 196939 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 22436 | lr 0.25 | gnorm 0.117 | clip 96% | oom 0 | wall 3304 | train_wall 2775\u001b[0m\n",
      "\u001b[31m| epoch 158 | valid on 'valid' subset | valid_loss 4.17507 | valid_nll_loss 2.71409 | valid_ppl 6.56 | num_updates 22436 | best 4.17507\u001b[0m\n",
      "\u001b[31m| epoch 159 | loss 3.946 | nll_loss 2.463 | ppl 5.51 | wps 197899 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 22578 | lr 0.25 | gnorm 0.118 | clip 99% | oom 0 | wall 3324 | train_wall 2793\u001b[0m\n",
      "\u001b[31m| epoch 159 | valid on 'valid' subset | valid_loss 4.16995 | valid_nll_loss 2.71376 | valid_ppl 6.56 | num_updates 22578 | best 4.16995\u001b[0m\n",
      "\u001b[31m| epoch 160 | loss 3.945 | nll_loss 2.462 | ppl 5.51 | wps 195964 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 22720 | lr 0.25 | gnorm 0.116 | clip 98% | oom 0 | wall 3345 | train_wall 2810\u001b[0m\n",
      "\u001b[31m| epoch 160 | valid on 'valid' subset | valid_loss 4.1692 | valid_nll_loss 2.71321 | valid_ppl 6.56 | num_updates 22720 | best 4.1692\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 161 | loss 3.943 | nll_loss 2.460 | ppl 5.50 | wps 193856 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 22862 | lr 0.25 | gnorm 0.117 | clip 96% | oom 0 | wall 3367 | train_wall 2828\u001b[0m\n",
      "\u001b[31m| epoch 161 | valid on 'valid' subset | valid_loss 4.18098 | valid_nll_loss 2.71744 | valid_ppl 6.58 | num_updates 22862 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 162 | loss 3.941 | nll_loss 2.458 | ppl 5.49 | wps 194801 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 23004 | lr 0.25 | gnorm 0.119 | clip 97% | oom 0 | wall 3388 | train_wall 2845\u001b[0m\n",
      "\u001b[31m| epoch 162 | valid on 'valid' subset | valid_loss 4.17317 | valid_nll_loss 2.71119 | valid_ppl 6.55 | num_updates 23004 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 163 | loss 3.940 | nll_loss 2.457 | ppl 5.49 | wps 196551 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 23146 | lr 0.25 | gnorm 0.116 | clip 96% | oom 0 | wall 3408 | train_wall 2863\u001b[0m\n",
      "\u001b[31m| epoch 163 | valid on 'valid' subset | valid_loss 4.17511 | valid_nll_loss 2.7108 | valid_ppl 6.55 | num_updates 23146 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 164 | loss 3.939 | nll_loss 2.455 | ppl 5.48 | wps 192476 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 23288 | lr 0.25 | gnorm 0.119 | clip 96% | oom 0 | wall 3429 | train_wall 2881\u001b[0m\n",
      "\u001b[31m| epoch 164 | valid on 'valid' subset | valid_loss 4.17502 | valid_nll_loss 2.71364 | valid_ppl 6.56 | num_updates 23288 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 165 | loss 3.937 | nll_loss 2.453 | ppl 5.47 | wps 197126 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 23430 | lr 0.25 | gnorm 0.117 | clip 97% | oom 0 | wall 3450 | train_wall 2898\u001b[0m\n",
      "\u001b[31m| epoch 165 | valid on 'valid' subset | valid_loss 4.17232 | valid_nll_loss 2.70621 | valid_ppl 6.53 | num_updates 23430 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 166 | loss 3.935 | nll_loss 2.451 | ppl 5.47 | wps 193379 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 23572 | lr 0.25 | gnorm 0.118 | clip 96% | oom 0 | wall 3471 | train_wall 2916\u001b[0m\n",
      "\u001b[31m| epoch 166 | valid on 'valid' subset | valid_loss 4.175 | valid_nll_loss 2.71577 | valid_ppl 6.57 | num_updates 23572 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 167 | loss 3.933 | nll_loss 2.448 | ppl 5.46 | wps 193896 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 23714 | lr 0.25 | gnorm 0.118 | clip 96% | oom 0 | wall 3492 | train_wall 2933\u001b[0m\n",
      "\u001b[31m| epoch 167 | valid on 'valid' subset | valid_loss 4.17065 | valid_nll_loss 2.70778 | valid_ppl 6.53 | num_updates 23714 | best 4.1692\u001b[0m\n",
      "\u001b[31m| epoch 168 | loss 3.932 | nll_loss 2.448 | ppl 5.46 | wps 196869 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 23856 | lr 0.25 | gnorm 0.117 | clip 97% | oom 0 | wall 3513 | train_wall 2951\u001b[0m\n",
      "\u001b[31m| epoch 168 | valid on 'valid' subset | valid_loss 4.16751 | valid_nll_loss 2.70847 | valid_ppl 6.54 | num_updates 23856 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 169 | loss 3.930 | nll_loss 2.445 | ppl 5.45 | wps 195140 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 23998 | lr 0.25 | gnorm 0.117 | clip 94% | oom 0 | wall 3534 | train_wall 2968\u001b[0m\n",
      "\u001b[31m| epoch 169 | valid on 'valid' subset | valid_loss 4.16989 | valid_nll_loss 2.70606 | valid_ppl 6.53 | num_updates 23998 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 170 | loss 3.928 | nll_loss 2.443 | ppl 5.44 | wps 196479 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 24140 | lr 0.25 | gnorm 0.116 | clip 93% | oom 0 | wall 3555 | train_wall 2986\u001b[0m\n",
      "\u001b[31m| epoch 170 | valid on 'valid' subset | valid_loss 4.17103 | valid_nll_loss 2.70924 | valid_ppl 6.54 | num_updates 24140 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 171 | loss 3.928 | nll_loss 2.443 | ppl 5.44 | wps 193909 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 24282 | lr 0.25 | gnorm 0.118 | clip 98% | oom 0 | wall 3576 | train_wall 3003\u001b[0m\n",
      "\u001b[31m| epoch 171 | valid on 'valid' subset | valid_loss 4.17041 | valid_nll_loss 2.70365 | valid_ppl 6.51 | num_updates 24282 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 172 | loss 3.925 | nll_loss 2.440 | ppl 5.42 | wps 196134 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 24424 | lr 0.25 | gnorm 0.116 | clip 93% | oom 0 | wall 3597 | train_wall 3021\u001b[0m\n",
      "\u001b[31m| epoch 172 | valid on 'valid' subset | valid_loss 4.16786 | valid_nll_loss 2.70806 | valid_ppl 6.53 | num_updates 24424 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 173 | loss 3.927 | nll_loss 2.441 | ppl 5.43 | wps 196292 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 24566 | lr 0.25 | gnorm 0.118 | clip 96% | oom 0 | wall 3617 | train_wall 3038\u001b[0m\n",
      "\u001b[31m| epoch 173 | valid on 'valid' subset | valid_loss 4.17752 | valid_nll_loss 2.71067 | valid_ppl 6.55 | num_updates 24566 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 174 | loss 3.924 | nll_loss 2.438 | ppl 5.42 | wps 193369 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 24708 | lr 0.25 | gnorm 0.116 | clip 96% | oom 0 | wall 3638 | train_wall 3056\u001b[0m\n",
      "\u001b[31m| epoch 174 | valid on 'valid' subset | valid_loss 4.16894 | valid_nll_loss 2.70286 | valid_ppl 6.51 | num_updates 24708 | best 4.16751\u001b[0m\n",
      "\u001b[31m| epoch 175 | loss 3.922 | nll_loss 2.436 | ppl 5.41 | wps 192942 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 24850 | lr 0.25 | gnorm 0.117 | clip 98% | oom 0 | wall 3660 | train_wall 3074\u001b[0m\n",
      "\u001b[31m| epoch 175 | valid on 'valid' subset | valid_loss 4.16674 | valid_nll_loss 2.7029 | valid_ppl 6.51 | num_updates 24850 | best 4.16674\u001b[0m\n",
      "\u001b[31m| epoch 176 | loss 3.920 | nll_loss 2.433 | ppl 5.40 | wps 192095 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 24992 | lr 0.25 | gnorm 0.116 | clip 96% | oom 0 | wall 3681 | train_wall 3092\u001b[0m\n",
      "\u001b[31m| epoch 176 | valid on 'valid' subset | valid_loss 4.16998 | valid_nll_loss 2.7041 | valid_ppl 6.52 | num_updates 24992 | best 4.16674\u001b[0m\n",
      "\u001b[31m| epoch 177 | loss 3.919 | nll_loss 2.432 | ppl 5.40 | wps 195025 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 25134 | lr 0.25 | gnorm 0.116 | clip 98% | oom 0 | wall 3702 | train_wall 3109\u001b[0m\n",
      "\u001b[31m| epoch 177 | valid on 'valid' subset | valid_loss 4.16479 | valid_nll_loss 2.7021 | valid_ppl 6.51 | num_updates 25134 | best 4.16479\u001b[0m\n",
      "\u001b[31m| epoch 178 | loss 3.918 | nll_loss 2.431 | ppl 5.39 | wps 196884 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 25276 | lr 0.25 | gnorm 0.115 | clip 96% | oom 0 | wall 3723 | train_wall 3127\u001b[0m\n",
      "\u001b[31m| epoch 178 | valid on 'valid' subset | valid_loss 4.16027 | valid_nll_loss 2.70219 | valid_ppl 6.51 | num_updates 25276 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 179 | loss 3.916 | nll_loss 2.429 | ppl 5.38 | wps 194908 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 25418 | lr 0.25 | gnorm 0.115 | clip 95% | oom 0 | wall 3744 | train_wall 3144\u001b[0m\n",
      "\u001b[31m| epoch 179 | valid on 'valid' subset | valid_loss 4.17297 | valid_nll_loss 2.70305 | valid_ppl 6.51 | num_updates 25418 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 180 | loss 3.915 | nll_loss 2.426 | ppl 5.38 | wps 194720 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 25560 | lr 0.25 | gnorm 0.115 | clip 94% | oom 0 | wall 3765 | train_wall 3162\u001b[0m\n",
      "\u001b[31m| epoch 180 | valid on 'valid' subset | valid_loss 4.16604 | valid_nll_loss 2.70108 | valid_ppl 6.50 | num_updates 25560 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 181 | loss 3.914 | nll_loss 2.426 | ppl 5.38 | wps 196143 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 25702 | lr 0.25 | gnorm 0.115 | clip 92% | oom 0 | wall 3785 | train_wall 3180\u001b[0m\n",
      "\u001b[31m| epoch 181 | valid on 'valid' subset | valid_loss 4.1621 | valid_nll_loss 2.70196 | valid_ppl 6.51 | num_updates 25702 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 182 | loss 3.913 | nll_loss 2.425 | ppl 5.37 | wps 197532 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 25844 | lr 0.25 | gnorm 0.116 | clip 95% | oom 0 | wall 3806 | train_wall 3197\u001b[0m\n",
      "\u001b[31m| epoch 182 | valid on 'valid' subset | valid_loss 4.16775 | valid_nll_loss 2.70195 | valid_ppl 6.51 | num_updates 25844 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 183 | loss 3.912 | nll_loss 2.424 | ppl 5.37 | wps 192110 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 25986 | lr 0.25 | gnorm 0.117 | clip 96% | oom 0 | wall 3827 | train_wall 3215\u001b[0m\n",
      "\u001b[31m| epoch 183 | valid on 'valid' subset | valid_loss 4.16259 | valid_nll_loss 2.6972 | valid_ppl 6.49 | num_updates 25986 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 184 | loss 3.909 | nll_loss 2.420 | ppl 5.35 | wps 195191 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 26128 | lr 0.25 | gnorm 0.114 | clip 96% | oom 0 | wall 3848 | train_wall 3233\u001b[0m\n",
      "\u001b[31m| epoch 184 | valid on 'valid' subset | valid_loss 4.16097 | valid_nll_loss 2.6998 | valid_ppl 6.50 | num_updates 26128 | best 4.16027\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m| epoch 185 | loss 3.910 | nll_loss 2.422 | ppl 5.36 | wps 196490 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 26270 | lr 0.25 | gnorm 0.116 | clip 94% | oom 0 | wall 3869 | train_wall 3250\u001b[0m\n",
      "\u001b[31m| epoch 185 | valid on 'valid' subset | valid_loss 4.17393 | valid_nll_loss 2.70348 | valid_ppl 6.51 | num_updates 26270 | best 4.16027\u001b[0m\n",
      "\u001b[31m| epoch 186 | loss 3.908 | nll_loss 2.419 | ppl 5.35 | wps 195824 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 26412 | lr 0.25 | gnorm 0.116 | clip 95% | oom 0 | wall 3890 | train_wall 3267\u001b[0m\n",
      "\u001b[31m| epoch 186 | valid on 'valid' subset | valid_loss 4.15678 | valid_nll_loss 2.69467 | valid_ppl 6.47 | num_updates 26412 | best 4.15678\u001b[0m\n",
      "\u001b[31m| epoch 187 | loss 3.907 | nll_loss 2.418 | ppl 5.34 | wps 196470 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 26554 | lr 0.25 | gnorm 0.114 | clip 92% | oom 0 | wall 3911 | train_wall 3285\u001b[0m\n",
      "\u001b[31m| epoch 187 | valid on 'valid' subset | valid_loss 4.16455 | valid_nll_loss 2.69942 | valid_ppl 6.50 | num_updates 26554 | best 4.15678\u001b[0m\n",
      "\u001b[31m| epoch 188 | loss 3.905 | nll_loss 2.416 | ppl 5.34 | wps 196350 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 26696 | lr 0.25 | gnorm 0.115 | clip 96% | oom 0 | wall 3931 | train_wall 3302\u001b[0m\n",
      "\u001b[31m| epoch 188 | valid on 'valid' subset | valid_loss 4.16384 | valid_nll_loss 2.69843 | valid_ppl 6.49 | num_updates 26696 | best 4.15678\u001b[0m\n",
      "\u001b[31m| epoch 189 | loss 3.904 | nll_loss 2.415 | ppl 5.33 | wps 194463 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 26838 | lr 0.25 | gnorm 0.116 | clip 94% | oom 0 | wall 3952 | train_wall 3320\u001b[0m\n",
      "\u001b[31m| epoch 189 | valid on 'valid' subset | valid_loss 4.15458 | valid_nll_loss 2.69633 | valid_ppl 6.48 | num_updates 26838 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 190 | loss 3.901 | nll_loss 2.411 | ppl 5.32 | wps 194581 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 26980 | lr 0.25 | gnorm 0.115 | clip 95% | oom 0 | wall 3973 | train_wall 3338\u001b[0m\n",
      "\u001b[31m| epoch 190 | valid on 'valid' subset | valid_loss 4.16265 | valid_nll_loss 2.69761 | valid_ppl 6.49 | num_updates 26980 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 191 | loss 3.901 | nll_loss 2.410 | ppl 5.32 | wps 195966 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 27122 | lr 0.25 | gnorm 0.114 | clip 94% | oom 0 | wall 3994 | train_wall 3355\u001b[0m\n",
      "\u001b[31m| epoch 191 | valid on 'valid' subset | valid_loss 4.1584 | valid_nll_loss 2.69302 | valid_ppl 6.47 | num_updates 27122 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 192 | loss 3.901 | nll_loss 2.411 | ppl 5.32 | wps 196697 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 27264 | lr 0.25 | gnorm 0.116 | clip 90% | oom 0 | wall 4015 | train_wall 3372\u001b[0m\n",
      "\u001b[31m| epoch 192 | valid on 'valid' subset | valid_loss 4.15866 | valid_nll_loss 2.69291 | valid_ppl 6.47 | num_updates 27264 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 193 | loss 3.899 | nll_loss 2.409 | ppl 5.31 | wps 193061 | ups 6.7 | wpb 27811 | bsz 1128 | num_updates 27406 | lr 0.25 | gnorm 0.113 | clip 98% | oom 0 | wall 4036 | train_wall 3390\u001b[0m\n",
      "\u001b[31m| epoch 193 | valid on 'valid' subset | valid_loss 4.16202 | valid_nll_loss 2.69863 | valid_ppl 6.49 | num_updates 27406 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 194 | loss 3.898 | nll_loss 2.408 | ppl 5.31 | wps 194016 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 27548 | lr 0.25 | gnorm 0.114 | clip 96% | oom 0 | wall 4057 | train_wall 3408\u001b[0m\n",
      "\u001b[31m| epoch 194 | valid on 'valid' subset | valid_loss 4.16299 | valid_nll_loss 2.69488 | valid_ppl 6.48 | num_updates 27548 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 195 | loss 3.897 | nll_loss 2.406 | ppl 5.30 | wps 194856 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 27690 | lr 0.25 | gnorm 0.113 | clip 92% | oom 0 | wall 4078 | train_wall 3426\u001b[0m\n",
      "\u001b[31m| epoch 195 | valid on 'valid' subset | valid_loss 4.15947 | valid_nll_loss 2.69694 | valid_ppl 6.48 | num_updates 27690 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 196 | loss 3.895 | nll_loss 2.404 | ppl 5.29 | wps 197669 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 27832 | lr 0.25 | gnorm 0.115 | clip 93% | oom 0 | wall 4099 | train_wall 3443\u001b[0m\n",
      "\u001b[31m| epoch 196 | valid on 'valid' subset | valid_loss 4.15722 | valid_nll_loss 2.69315 | valid_ppl 6.47 | num_updates 27832 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 197 | loss 3.893 | nll_loss 2.401 | ppl 5.28 | wps 194652 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 27974 | lr 0.25 | gnorm 0.114 | clip 96% | oom 0 | wall 4120 | train_wall 3461\u001b[0m\n",
      "\u001b[31m| epoch 197 | valid on 'valid' subset | valid_loss 4.16452 | valid_nll_loss 2.69769 | valid_ppl 6.49 | num_updates 27974 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 198 | loss 3.893 | nll_loss 2.402 | ppl 5.28 | wps 194388 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 28116 | lr 0.25 | gnorm 0.114 | clip 88% | oom 0 | wall 4141 | train_wall 3479\u001b[0m\n",
      "\u001b[31m| epoch 198 | valid on 'valid' subset | valid_loss 4.15852 | valid_nll_loss 2.69358 | valid_ppl 6.47 | num_updates 28116 | best 4.15458\u001b[0m\n",
      "\u001b[31m| epoch 199 | loss 3.893 | nll_loss 2.401 | ppl 5.28 | wps 195200 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 28258 | lr 0.25 | gnorm 0.116 | clip 95% | oom 0 | wall 4162 | train_wall 3496\u001b[0m\n",
      "\u001b[31m| epoch 199 | valid on 'valid' subset | valid_loss 4.15176 | valid_nll_loss 2.69166 | valid_ppl 6.46 | num_updates 28258 | best 4.15176\u001b[0m\n",
      "\u001b[31m| epoch 200 | loss 3.890 | nll_loss 2.398 | ppl 5.27 | wps 198161 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 28400 | lr 0.25 | gnorm 0.112 | clip 92% | oom 0 | wall 4182 | train_wall 3513\u001b[0m\n",
      "\u001b[31m| epoch 200 | valid on 'valid' subset | valid_loss 4.15642 | valid_nll_loss 2.69221 | valid_ppl 6.46 | num_updates 28400 | best 4.15176\u001b[0m\n",
      "\u001b[31m| epoch 201 | loss 3.865 | nll_loss 2.370 | ppl 5.17 | wps 197746 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 28542 | lr 0.025 | gnorm 0.108 | clip 76% | oom 0 | wall 4203 | train_wall 3531\u001b[0m\n",
      "\u001b[31m| epoch 201 | valid on 'valid' subset | valid_loss 4.14573 | valid_nll_loss 2.67711 | valid_ppl 6.40 | num_updates 28542 | best 4.14573\u001b[0m\n",
      "\u001b[31m| epoch 202 | loss 3.851 | nll_loss 2.355 | ppl 5.11 | wps 197138 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 28684 | lr 0.0025 | gnorm 0.106 | clip 68% | oom 0 | wall 4224 | train_wall 3548\u001b[0m\n",
      "\u001b[31m| epoch 202 | valid on 'valid' subset | valid_loss 4.14629 | valid_nll_loss 2.67609 | valid_ppl 6.39 | num_updates 28684 | best 4.14573\u001b[0m\n",
      "\u001b[31m| epoch 203 | loss 3.848 | nll_loss 2.351 | ppl 5.10 | wps 197321 | ups 6.9 | wpb 27811 | bsz 1128 | num_updates 28826 | lr 0.00025 | gnorm 0.104 | clip 64% | oom 0 | wall 4244 | train_wall 3566\u001b[0m\n",
      "\u001b[31m| epoch 203 | valid on 'valid' subset | valid_loss 4.1448 | valid_nll_loss 2.67558 | valid_ppl 6.39 | num_updates 28826 | best 4.1448\u001b[0m\n",
      "\u001b[31m| epoch 204 | loss 3.848 | nll_loss 2.352 | ppl 5.10 | wps 196912 | ups 6.8 | wpb 27811 | bsz 1128 | num_updates 28968 | lr 2.5e-05 | gnorm 0.103 | clip 61% | oom 0 | wall 4265 | train_wall 3583\u001b[0m\n",
      "\u001b[31m| epoch 204 | valid on 'valid' subset | valid_loss 4.14466 | valid_nll_loss 2.67555 | valid_ppl 6.39 | num_updates 28968 | best 4.14466\u001b[0m\n",
      "\u001b[31m| done training in 4264.1 seconds\u001b[0m\n",
      "\u001b[31mTraining complete.\u001b[0m\n",
      "\u001b[32mTraining complete.\u001b[0m\n",
      "\n",
      "2019-06-28 23:22:21 Uploading - Uploading generated training model\n",
      "2019-06-28 23:54:30 Completed - Training job completed\n",
      "Billable seconds: 12661\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model has finished training, we can go ahead and test its translation capabilities by deploying it on an endpoint.\n",
    "\n",
    "## Hosting the model\n",
    "\n",
    "We first need to define a base JSONPredictor class that will help us with sending predictions to the model once it's hosted on the Amazon SageMaker endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import RealTimePredictor, json_serializer, json_deserializer\n",
    "\n",
    "class JSONPredictor(RealTimePredictor):\n",
    "    def __init__(self, endpoint_name, sagemaker_session):\n",
    "        super(JSONPredictor, self).__init__(endpoint_name, sagemaker_session, json_serializer, json_deserializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the estimator object to deploy the model artificats (the trained model), and deploy it on a CPU instance as we no longer need a GPU instance for simply infering from the model. Let's use a `ml.m5.xlarge`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "#predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m5.12xlarge', predictor_cls=JSONPredictor)\n",
    "\n",
    "## modifications by nigenda@ (Sagemaker Hosting on-call)\n",
    "## per https://sagemaker.readthedocs.io/en/stable/estimators.html#sagemaker.estimator.Estimator.deploy\n",
    "## the endpoint reuses the training name if no name is defined, therefore when retrying endpoint creation you should do:\n",
    "nigenda_predictor = estimator.deploy(initial_instance_count=1, endpoint_name=\"pytorch-fairseq-20190715T14\", instance_type='ml.m5.12xlarge', predictor_cls=JSONPredictor)\n",
    "## that or let the estimator update the existing endpoint\n",
    "# predictor = estimator.deploy(initial_instance_count=1, update_endpoint=True, instance_type='ml.m5.12xlarge', predictor_cls=JSONPredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now it's your time to play. Input a sentence in German and get the translation in English by simply calling predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's the same .\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "text_input = 'Guten Morgen'\n",
    "\n",
    "result = nigenda_predictor.predict(text_input)\n",
    "#  Some characters are escaped HTML-style requiring to unescape them before printing\n",
    "print(html.unescape(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you're done with getting predictions, remember to shut down your endpoint as you no longer need it. \n",
    "\n",
    "## Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e1cae36713f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "sagemaker_session.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila! For more information, you can check out the [FAIRSeq toolkit homepage](https://github.com/pytorch/fairseq). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
